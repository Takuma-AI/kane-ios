# AI's Trillion-Dollar Opportunity: Sequoia AI Ascent 2025 Keynote

**Channel**: Sequoia Capital  
**Date**: 2025-05-07  
**URL**: https://www.youtube.com/watch?v=v9JBMnxuPX8  
**Transcribed**: 2025-08-20

---

## Transcript

All right, my name is Packer A.D. I'm a partner at Sequoia, Sonya and Constantine.
And all of our partners at Sequoia will be your host for the day.
Now, before we get into the real meat of the day, me and Sonya and Constantine are going
to just share a few perspectives on some of the things that we've learned over the last
year or so.
And we're painfully aware that we're the appetizer, not the entree.
I got an email from one of the founders that I worked with yesterday who said, oh, hey,
man, I'm going to be a little bit late to this thing.
I'll probably show up at like 9.35.
And I was like, well, that's oddly specific.
That's exactly when Jensen comes on.
And so, so look, we get it.
But we're going to share a couple thoughts and then we'll get into the real stuff.
All right.
First off, some calibration.
What do we think is going on in the world of AI?
Simple framework that we use to look at markets.
What is it?
The Don Valentine question.
So what?
Why does it matter?
Why now?
It may be inevitable, but is it imminent?
And then finally, what now?
What do we do?
How do we take advantage of this?
How do we play to win?
And we've talked about each of these in years past, but we're going to update some of
our thinking over the next couple of minutes here.
And I actually, I have to be honest with you, I had a real banger on the what.
Constantine delicately suggested that telling a roomful of AI people what AI is, not a
great idea.
So we're actually going to jump straight to the so what?
OK, just for fun.
Who remembers this slide from last year?
All right.
Thank you.
Wonderful.
Top row.
Cloud transition.
Bottom row.
AI transition.
Left side of the page.
Yesterday.
Middle of the page.
Today.
Right side of the page.
Tomorrow.
What does it say?
It says that the cloud at 400 billion of revenue is bigger than the global software market
when that transition began.
If we reasoned by analogy, the market we're going after in the world of AI, services,
the starting point is at least an order of magnitude bigger.
The end point, 10 or 20 years from now, has a chance to be absolutely massive.
Important point.
Now, we've actually updated our thinking.
It's not just the services market that AI is going after.
It's both services and software.
Means that both of these profit pools are under attack.
We've seen plenty of companies that start with software, gets a little bit smarter, becomes
more of a co-pilot, gets a little bit smarter, becomes more of an autopilot, and they actually
progress from selling a tool into software budget to selling an outcome, to selling work
into labor budget.
Both of these tams are up for grabs.
Okay.
Who remembers this slide from last year?
Oh, man.
I'm a little sad.
Those are only like three or four people.
All right.
There's one more.
All right.
Thank you.
Don't get bashful.
You guys can raise your hands.
Okay.
It represents the waves of technology that have stacked up over the last several decades
to bring us to the present moment.
There are two points to this slide.
One, AI is, in fact, imminent, not just inevitable.
The present conditions are in place.
Compute, networks, data, distribution, talent.
We have all the ingredients we need, so we're ready to go.
Second point of this slide, these waves tend to be additive, and so the opportunity is
much bigger than it's been for prior waves.
It's also coming much faster.
Now I hate this slide.
X-axis, time, y-axis, vanity metric.
People use this to justify all manner of sense, okay?
But the observation is correct.
These are happening faster and faster and faster than they had before, but not a lot
of people have dug in on why.
And so we just want to take a second on it.
If you think about the physics of distribution, you just need three things.
People have to know about your thing.
They have to want your thing, and they have to be able to buy your thing.
That's it.
Does anybody remember that logo?
When the cloud transition got going, nobody was paying attention.
Benioff had to do these crazy gorilla marketing tactics to get anybody to pay attention.
AI is very different.
November 30, 2022, Chatchee PT comes out.
The entire world is paying attention to AI.
Middle column.
These are the combined monthly active users for Reddit and the artist formerly known as
Twitter.
It didn't exist at the start of the cloud transition, barely existed at the start of
the mobile transition.
Somewhere between 1.2 and 1.8 billion people on these platforms today.
Not the only way to find out about cool stuff, but a pretty good way to find out about
cool stuff.
Right side of the page, let's imagine you listen to Benioff.
There are only 200 million people connected to the internet.
Today it's 5.6 billion.
It's effectively every household and every business in the world.
And so what does all this mean?
It means the rails are in place.
And when the starting gun went off, there were no barriers to adoption.
This is not an AI specific phenomenon.
This is the new reality of technology distribution, the physics have changed.
Train tracks are in place.
Okay, another slide from last year.
What do we do about it?
Where do we play to win?
Two points on this slide.
Number one.
A lot of white space.
Again, this is a slide from last year.
There's a little less white space now.
People are starting to break out.
But for the most part, the opportunity is still white open.
Point number two.
These logos represent the companies that got to a billion plus of revenue.
We don't care about unicorns, we care about revenue and free cash flow, got to a billion
plus of revenue during prior transitions.
Most of them are at the top of the page.
Most of them are at the application layer.
We have believed and we continue to believe that the same will be true for AI.
The value is at the application layer.
But guess what?
You got competition.
We got a second scaling law.
We got test time compute.
We got reasoning with tool use and inter agent communication.
That allows the foundation models to get pretty far into the application layer.
What do you do if you're a startup and you're not building a vertically integrated business?
Go from the customer back.
Think vertical specific.
Think function specific.
Think with complex problems, it might require human in the loop.
But this is the race.
This is where the value is going to be.
This should be top of mind for everybody.
How do we play to win?
All right.
Come on, you guys can laugh.
This is a good one.
All right.
How do we play to win?
Well, we showed this last year, so I'll presume you're not laughing because you saw it
last year.
So, 95% of building a company in AI is just building a company.
It's the same old stuff.
It's all an important problem in a unique and compelling way.
Get great people to follow you, all that good stuff.
The other 5% is AI specific.
And in the context of that race for the application layer, there are a few things to consider.
This is the Leoni merchandising cycle.
Our partner Doug Leoni, the goat, spent 40 years lovingly crafting this little piece
of content.
This represents everything you need to take an idea in your brain and turn it into a product
in the hand of your customers, okay?
That idea has to turn into a product that has to be built by an engineering team that
has to be taken to market and sold and supported.
This is the value chain.
Bottom of this page is the tech out point of view.
Top of this page is the customer back point of view.
That's how you can build modes across the entire value chain.
Your customer is not sure what they want out of AI.
You can have an opinion.
You can give them an end to end solution that just solves the problem as opposed to throwing
a tool over the fence.
You can build data flywheels with the usage data of your own product.
That's something that nobody else has.
You can be of the industry for the industry, kind of like what open evidence does for the
medical industry.
You can speak their language, Harvey sends lawyers in to talk with law firms.
You got to be honest with you, we wouldn't recommend for deployed engineers, but you can
do it.
Tough way to live, but you can do it.
You can put a big bear hug around your customers in a way that foundation models probably
won't.
By the way, we love foundation models too, but we're assuming that most of you are not building
foundation models.
Most of you are building applications.
Okay.
I have two more slides, then we'll hand it off.
So we can ask the question a lot, what do you look for in AI companies?
And again, 95% of it is the same stuff that we look for in any company.
Okay.
Here's the 5% that's AI specific.
Point number one, revenue.
Vibrevenue can kill you.
Everybody loves Vibrevenue.
It feels so good.
Oh my God, we have so much revenue.
Go look at it.
Okay.
Is it tire kicking?
Are you actually creating durable behavior change?
Okay.
Oh, I don't have the metrics to do that.
Yes, you do.
Respect the adoption, the engagement, the retention, what are people actually doing
with your products?
And don't delude yourself in a thinking you have real revenue when you have Vibrevenue
because it'll bite you, okay?
The good vibes piece of this is important too.
Actually real quick.
Andrew Reed.
Are you in here?
Vibeshack.
How are we doing?
How's everybody doing?
I don't care about you.
How's everybody doing?
Impackable.
I heard impeccable vibes.
Okay.
Good.
You need good vibes to their customers.
What does it mean?
Your customers have to trust you and you have to earn that trust.
This is more important than your product at this point in time.
Where we are in the cycle.
The products will get better.
If they trust you to make it better, you're in good shape.
If they don't trust you to make it better, you're in bad shape.
Point number two, margins.
We don't necessarily care where your gross margin is today.
The cogs component of that is probably going to keep going down.
Cosper token is down 99% in the last 12 to 18 months.
That cost curve is going to continue.
Those cogs are going to go down.
I know it's stepping up with test time compute and all that, but that's going to go down
to the price component of that.
If you are successfully marching from selling a tool to selling an outcome and you're going
up that value chain and you can capture more of that value, your price point is probably
going to go up to.
Your gross margins may not be great today, but you should have a good path to really healthy
gross margins over time.
Point number three, data flywheel.
Raise your hand if you got a data flywheel.
That business metric does that data flywheel move.
Okay, I see less certainty.
I got good news, I got bad news.
Good news is, if you can't answer that question, I still love you.
The bad news is your data flywheel is bullshit.
Either you don't have a data flywheel or it just doesn't matter.
It needs to tie to a business metric or it just doesn't matter.
This is really important because this is one of the best modes that you can build.
Last slide.
Who can tell me how these two things go together?
I'd be really impressed if you can't.
It's not logical at all.
All right.
Nature hits a vacuum.
There is, we'll get there.
Nature hits a vacuum.
There is a tremendous sucking sound in the market right now for AI.
All of the macroeconomic stuff, tariffs and interest rate, noise doesn't matter.
The rising tide of technology adoption absolutely swamps any of the volatility that you see
in the markets.
Ignore it.
Okay.
There is a tremendous sucking sound in the market.
And if you don't get in front of it, somebody else will because nature hates a vacuum.
And so all the stuff we just said about modes and metrics and whatever, notwithstanding,
you are in a run-like heck business right now.
Now is the time to go at maximum velocity all of the time.
Thank you, Pat.
So I'm going to use my section to focus on what's happening with AI right now.
And we'll start with a quick year in review, both from the customer back and from the technology
out.
That's a year in review.
Back in 2023, we showed this chart of the ratio of daily to monthly active users for AI
native applications versus for traditional mobile apps.
And the punchline at the time was that AI apps had terrible engagement ratios, hype exceeded
reality in the data.
We're very pleased to report that that punchline has now changed dramatically.
It's been stunning to see, for example, the daily monthly active ratio for chat GPT
climbed the curve and now getting close to reddit levels.
I think this is extremely good news.
It means that more and more of us are getting value out of AI.
And we're all climbing the ladder together on how to weave AI into our daily lives.
And sometimes that usage is good and fun.
I personally melted an embarrassing number of GPUs trying to jiblify everything.
But while the jibli moment was fun and it was viral, the more exciting thing is all the
deeper things that were just scratching the surface of.
So for example, advertising, the ability to create stunningly accurate and beautiful
ad copy, education, the ability to visualize new concepts with the snap of a finger, health
care, the ability to diagnose patients better with an app like open evidence.
We're just scratching the surface of what's possible.
And as the AI models become more and more capable, the things we can do with them through
this front door become more and more profound.
OK, who here is saying the movie her?
OK.
And we have Brendan in the audience today.
We still don't have AI Scar Jo, but 2024 gave us what I would call the her moment for
voice.
And voice generation went from almost there to fully crossing the uncanny valley.
I've had a few folks say that, but keep your cards close to your chest.
Let's see if I can truly blow your mind.
Have you ever seen the movie her?
Oh, yeah.
Her.
Classic.
Walking Phoenix really nailed that falling for your OS thing, right?
Makes you wonder what the future holds.
Sesame's voice demo was incredible, friend, and I'm excited to see what you built.
And it's crazy how quickly the gap between science fiction and reality is closing on us.
And it feels like the touring test really just snuck up on us, actually had a tip for
that to Jim Fan who tweeted it and I stole it for this presentation.
So hi, Jim.
Finally, the breakout application category of the year was coding, which reached screaming
product market fit.
Anthropics, clawed three, five, sonnet, dropped last fall, triggering a rapid vibe shift
in the coding landscape.
And people are now using AI coding for really impressive things.
So for example, this person vibe coded their own docs and alternative.
And so whether you're a veteran 10X engineer or somebody who has no idea how to code,
we do think that AI is fundamentally changing the accessibility, the speed, and the economics
of software creation.
From the technology back, the bad news is that pre-training does seem to be slowing down.
We've scaled pre-training by 9 or 10 orders of magnitude since the AlexNet days.
And that means that a lot of the low hanging fruit has been picked.
The research ecosystem is finding new ways to break through.
The most important breakthrough was reasoning from OpenAI.
We were lucky enough to have no embrown from the strawberry team give us a preview of
what was going to happen with reasoning at AISN last year.
And this year we're happy to have Dan Roberts in the audience who's going to be giving
another talk on what's happening with O3 and reasoning ahead.
It's not just reasoning, it's synthetic data, it's tool use, it's a genetic scaffolding,
all of these things are combining, combining to create new ways for us to scale intelligence.
Anthropics MCP created strong ecosystem and networks, and we're also excited to see
what that does to accelerate a genetic tool use.
So all of this bigger base models, inference time reasoning, tool use, it's all combining
to create AI that's capable of increasingly sophisticated tasks.
The meter benchmark is one good quantitative measure of this, but I think what's even more
powerful is talking to each of you about the types of things that are only possible now
because of O3 or operator or deep research or Sonnet.
And then finally, a lot of the most exciting technology innovation in AI right now is
happening at that blurry boundary between research and product.
And I think the two breakthrough examples of this over the last year were deep research
and notebook LM.
And we're excited to have the creators of both of those products in the audience with us
today, Ryza and Jason from Notebook, we're creating a new company called Hux and Esafelford
from OpenAI.
OK.
Talk about where value will accrue in the AI stack.
I remember debating this question with my wonderful partners at Sequoia at the time.
I was personally the midwits in the middle of this chart saying, like, I don't know about
the GPD rappers.
And I remember my partners, Pat in particular, were adamant that the value was going to accrue
to the application layer.
And I remember thinking, like, OK, Pat, sure.
Good luck with that.
But having seen how the last few years have played out, I think you were right, Pat.
You belong over here.
Good job.
If you see where value has been created, if you see companies like Harvey and OpenEvidence
really creating that customer back value, we very much believe that the application layer
is where the value will ultimately accrue and that the battleground is intensifying in
this layer of the stack with the foundation models increasingly competing here.
OK.
Quick aside, the jokes actually on all of us, because the real undisputed king of the stack who
was making all the dollars was the goat himself, Jensen Huang, who were excited to hear from
shortly.
OK.
Back to the application layer.
We now think that the first cohort of AI's killer apps has emerged, whether it's Chatchy
BT, Harvey, Gleens, Sierra, Cursor, a bridge.
But there's a whole set of new companies on the rise across a very rich and diverse set
of end markets, including listen labs, including OpenEvidence.
We're excited to feature many of you today.
Another prediction is that many of these new companies will be agents first, and that
the agencies companies are selling will evolve from prototype so they're often just
pieced together today to ones that are really robust.
And we see two paths that companies are taking to build that.
Path one, orchestration with rigorous testing in the eVALS, path two, agents ten, tuned
on end-to-end tasks.
And we're excited to hear more on this from both Harrison of Langchain and Issa of OpenAI
today.
Our next prediction on the shape of agent companies in 2025 is vertical agents.
Vertical agents are a wonderful opportunity for startup founders who deeply understand
the domain.
And we see companies creating agents that are trained end-to-end to excel in a very
specific workflow, using techniques, including reinforcement learning on synthetic data and
user data, to make AI systems very performant at very specific tasks.
And the evidence we've seen so far makes us really optimistic.
In security, Expo is now showing that they have an agent that can outperform human penetration
testers.
In DevOps, traversal is showing that they can create an AI troubleshooter that is better
than the best human troubleshooters.
Same goes in networking with meter in networking engineers.
And so all of this, all these data points, they're early, but they make us very optimistic
that vertical agents trying to solve a very specific problem can outperform the best
humans today.
One final prediction on agents in 2025.
We're entering an abundance era.
Code as the first market category to tip will offer us a preview into what that abundance
era actually means.
What happens when labor is cheap and plentiful?
Are we going to get a bunch of AI slop?
And what happens when taste becomes the scarce asset?
We're excited to see the continued progress of coding agents and what that does to the
technology landscape, but also as a harbinger for how other industries will be changed by
AI.
I'll turn it over to Constantine.
Thank you, Sonya.
All right.
Great job.
All right.
Good morning, everyone.
Thank you, Sonya.
Thank you, Pat.
So we just talked about really big important topics, the so what?
Why does this matter so incredibly much?
What now?
What's going on in the world?
The state of AI today and it's immediate future.
Now we're going to take a step back.
We're going to think through predictions about what's coming in the mid and long term.
In this section, we'll have three parts.
We'll talk about what we see as the major next wave.
Then we'll get into the technology needed to achieve that wave.
And then finally, we'll talk about what it means for each of us, our day-to-day lives.
A year ago, AI sent was all about agents.
We were talking about agents and they were just beginning to form into businesses.
The topic was really these machine assistants that eventually we predicted would come together
as machine networks.
These machine networks are now broadly called agent swarms.
They play a role in many of your companies and are beginning to form into a really critical
part of the AI stack.
They're just working with each other against each other, collaborating, doing reasoning
with each other.
In the years to come, we think that this matures even further into an agent economy.
An agent economy is one which agents don't just communicate information.
They transfer resources.
They can make transactions.
They keep track of each other.
They understand trust and reliability and they actually have their own economy.
Well, this economy doesn't cut out humans.
It's all about humans.
The agents work with the people and the people work with the agents in this agent economy.
But in order to achieve that very big, important next wave that we're all going to enter, we
have a lot of important technical challenges and we'll talk about three of them.
Frankly, this room is going to be addressing those three as you build.
Well, the first is persistent identity.
When we talk about persistent identity, we really mean two things.
The first is the agent itself needs to be persistent.
If you're doing business with someone and they change day to day, you probably won't
be doing business with them for very long.
That dramatically different experience will take its toll.
The agent is going to have to be able to persist on its own personality and its own understanding.
The second type of persistence is understanding you.
Similarly, if you're doing business with a person and they don't remember anything about
you, they can hardly remember your name.
That's also a big challenge to trust and reliability.
Now, we've been trying everything from RAG and VectorDBs to really long context windows,
but ever in this room knows that there are still major challenges in true memory and
self-learning on that true memory and actually getting the agents to be able to be consistent
where it matters and only different in the areas where they should be differing.
The second major technology shift is we need to have seamless communication protocols.
Now the great news is everyone seems to be focused on this now, but imagine personal
computing without seamless communication protocols, no TCP IP, no internet.
We're just now building that protocol later and there's certainly a lot of excitement
around MCP.
It's so great to see the big players collaborating and working together to come up with this
is just one, but a series of protocols that are going to allow for transfer of information,
transfer of value and transfer of trust.
Finally, security.
This is a topic that's going to be on the rise and is certainly on top of many of your
minds.
If you can't meet the person you're doing business with, palm to palm, face to face, that importance
of security and trust is even further elevated.
You can't with agents.
So we're going to have an entire cottage industry formed around that trust, that security,
and it will be even more important in the agent economy than it already is in our current
economy.
So we talked about the technology needed to get to this big wave, to get to this agent
economy.
Now let's talk a little bit about what it's going to mean for each of us.
Well, first of all, it's going to change our mindsets.
And frankly, this room is already there on what we're calling the stochastic mindset.
The stochastic mindset is a departure from determinism.
You know, a lot of us fell in love with computer science because it was so deterministic, right?
You program the computer to do something, it does it, even if that results in a sag fault.
Now we're entering an error of computing that's going to be stochastic.
If you ask a computer to remember the number 73, it'll remember that tomorrow, next week, next month.
If you ask a person or an AI, well, it might remember 73.
It might remember 37, 72, 74, the next prime, 79, or nothing at all.
The point here is that this is going to be materially different thinking from what we've done
in the decades past.
Second change is a management mindset.
And this management mindset is going to be all about understanding what your agents can and can't do for you.
Everybody knows that being a really good IC engineer is pretty different from being a great engineering manager.
And this is going to be the transition that most of the economy is going to make into more complex,
managerial decisions like blocking processes and giving feedback.
And I really hope it doesn't result in year end reviews of agents.
Let's try to avoid that.
The third major change for each of us is a combination of the previous two.
Way more leverage with significantly less certainty.
We're entering a world where you can do more, but you have to be able to manage that uncertainty and manage risks.
And in this world, ever in this room is extremely well suited to thrive.
A year ago, at AI Cent, we talked about this chart.
And we were talking about leverage because we said individual functions at an organization will begin to have AI agents.
And then we predicted that these functions would begin to merge.
They cluster and entire processes would be completed by AI agents.
We even made the prediction that we'd have the first one person unicorn.
Now, that hasn't happened yet.
But we have seen companies scale faster than ever before with fewer people than ever before.
And we do think we're going to get to the highest level of leverage that we've ever seen as economy.
Eventually, these processes and agents are going to merge.
You're going to have neural networks within very large complex neural networks,
a network of these neural networks.
And this is going to change everything.
It's going to reinvent individual work.
It's going to rewire companies.
And it's going to recreate the economy.
Thank you all for joining us.
We're going to have an amazing AI Cent today and we're very grateful for you being with us.

---

*Transcribed using OpenAI Whisper (base model)*
