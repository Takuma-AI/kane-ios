# OpenAI's Sam Altman on Building the 'Core AI Subscription' for Your Life

**Speaker**: Sam Altman, CEO of OpenAI  
**Event**: Sequoia AI Ascent 2025  
**Date**: May 12, 2025  
**Duration**: 31:59  
**Transcription Date**: August 23, 2025  
**URL**: https://youtube.com/watch?v=ctcMA6chfDY

---

## Executive Summary

Sam Altman discusses OpenAI's journey from 14-person research lab to building the "core AI subscription," emphasizing forward-looking strategy over detailed planning. He outlines generational differences in AI usage, predicts agents-focused 2025, scientific discovery in 2026, and physical world robotics in 2027.

## The Journey: From Research Lab to Consumer Product

### 2016 Origins
> "We were sitting over there and there were, you know, 14 of us or something and you were hacking on this new system... this was a research lab with no with with a very strong belief and direction and conviction but no real kind of like action plan... not only was like the idea of a company or a product sort of unimaginable, the spec like LLMs as an idea were still very far off."

### The API-First Strategy
> "One of the things that I had just observed about uh companies products in general is if you do an API it usually works somehow on the upside... if you make something much easier to use, there's usually a huge benefit to that... we will hope that somebody else finds something to build."

### ChatGPT Genesis from Playground Usage
> "One thing we did notice which eventually led to ChatGpt is even though people couldn't build a lot of great businesses with the GPT3 API, people love to talk to it in the playground. And it was terrible at chat... but people loved to do it anyway."

## Strategic Philosophy: Forward-Looking vs Backward Planning

### Against Master Plans
> "There's no master plan beyond that... I am a big believer that you can kind of like do the things in front of you, but if you like try to work backwards from like kind of we have this crazy complex thing. Um that doesn't usually work as well."

### Nimble Tactics Philosophy
> "We pride ourselves on being like nimble and adjusting tactics as the world adjusts. And so the products um you know the products that we're going to build next year we're probably not even thinking about right now."

### Research Roadmap Confidence
> "I've actually never felt more optimistic about our research road map than I do right now."

## The Core AI Subscription Vision

### Platform Strategy
> "I I I think the way to model us is we want to build we want to be people's like core AI subscription and way to use that thing... we'll have a couple of other kind of like really key parts of that subscription. But mostly we will hopefully build this smarter and smarter model."

### Competitive Moat
> "If you can make a better Core AI subscription offering than us, go ahead. That'd be great."

### Future Integration Vision
> "I really hope that all of this merges into one thing. like you should be able to sign in with OpenAI to other services. Other services should have an incredible SDK to like take over the chat GBT um UI at some point."

## Organizational Scaling: Product Velocity at Scale

### Anti-Molasses Philosophy  
> "I I I think a mistake that a lot of companies make is they get big and they don't do any they don't do more things. So they just like get bigger because you're supposed to get bigger and they still ship the same amount of product. And that's when like the molasses really takes hold."

### Small Teams, High Responsibility
> "I I like I am a big believer that you want everyone to be busy. You want teams to be small. you want like to do a lot of things relative to the number of people you have otherwise you just have like 40 people in every meeting and huge fights over who gets like what tiny part of the product."

### The Necessity of Doing More
> "If you're going to grow you better do a lot more things otherwise you kind of just have a lot of people sitting in your room fighting or meeting or talking about whatever."

## Generational AI Usage Patterns

### The Operating System Generation
> "Gross oversimplification, but like older people use Chachi PT as a Google replacement. Maybe people in their 20s and 30s use it as like a life advisor something and then like people in college use it as an operating system."

### Young User Sophistication
> "They really do use it like an operating system. um they have like complex ways to set it up to connect it to like a bunch of files and they have like fairly complex prompts memorized in their head... they don't really make life decisions without asking like ChatGPT what they should do."

## Enterprise AI Transformation Challenges

### Creative Destruction Pattern
> "I I think this basically happens every major tech revolution... The thing that they're getting wrong is the same thing they always get wrong, which is like people get incredibly stuck in their ways."

### Institutional Resistance
> "You have like an information security council that meets once a year to decide what applications you're going to allow and what it means to like put data into a system, like it it's just it's so painful to watch what happens here."

### Prediction Timeline
> "My kind of prediction would be that there's another like couple of years of fighting pretending like this isn't going to reshape everything and then there's like a capitulation and a last minute scramble and it's sort of too late."

## Future Platform Architecture

### Federated Internet Vision
> "I hope something in between those that there is sort of like a new protocol on the level of HTTP for the future of the internet where things get federated and broken down into like much smaller components and agents are like constantly exposing and using different tools and authentication, payment, data transfer, it's all like built in at this level that everybody trusts."

### Platonic Ideal of Customization
> "The platonic ideal state is uh a very tiny reasoning model with a trillion tokens of context that you put your whole life into. The model never retrains. The weights never customize. But that thing can like reason across your whole context... every conversation you've ever had in your life, every book you've ever read, every email you've ever read."

## Voice and Code: Strategic Priorities

### Voice as Transformation Catalyst
> "I think voice is extremely important. Honestly, we just we have not made a good enough voice product yet... when we do, I think there's a not only is it cool with existing devices, but I I sort of think voice will enable a totally new class of devices if you can make it feel like truly human level voice."

### Coding as Core Infrastructure
> "Coding I think will be how these models kind of right now if you ask CHP a response, you get text back, maybe you get an image. Um, you would like to get a whole program back... writing code I think will be very central to how you like actuate the world and call a bunch of APIs."

## Research Lab Management Principles

### Historical Learning Approach
> "When we started OpenAI, we spent a lot of time trying to understand uh what a well-run research lab looks like. And you had to go really far back in the past. In fact, almost everyone that could like help advise us on this was dead."

### Bottom-Up vs Top-Down Balance
> "There are some projects that require so much coordination that there has to be a little bit of like top down quarterbacking, but I think most people try to do way too much of that."

### Principled Approach Success
> "I find it remarkable how much these few principles that we've tried to run our research lab on which we did not invent. We shamelessly copied from other good research labs in history um have worked for us."

## Timeline Predictions: 2025-2027

### 2025: The Year of Agents
> "I kind of think 2025 will be a year of sort of agents doing work. Coding in particular, I would expect to be a dominant category."

### 2026: Scientific Discovery
> "Next year is a year where I would expect more like uh sort of AI discovering new stuff and maybe we have AIs make some very large scientific discoveries or assist humans in doing that."

### 2027: Physical World Integration
> "Then 27 I I would guess is the year where like that all moves from the sort of intellectual realm to the physical world and robots go from a curiosity to like a serious economic creator of value."

## Founder Resilience and Crisis Management

### Resilience Building Over Time
> "It gets easier over time... the kind of challenges get harder and higher stakes but the emotional toll gets easier as you kind of go through more bad things... your ability to deal with them the sort of resilience you build up gets easier like with each one."

### Post-Crisis Psychology
> "The thing that I think is harder to sort of manage your own psychology through is the sort of like fallout after... The really valuable thing to learn is how you like pick up the pieces... not how you deal with the real crisis on day zero or day one or day two, but on day 60 as you're just trying to like rebuild after it."

## Key Strategic Insights

1. **Forward Planning**: Work forwards from current capabilities rather than backwards from grand visions
2. **Scale Without Molasses**: More people must mean more products/initiatives, not just bigger meetings
3. **Generational Adoption**: Young users are building operating system-level AI integration
4. **Platform Evolution**: From API to federated ecosystem with universal authentication and tools
5. **Timeline Clarity**: Agents (2025) → Scientific Discovery (2026) → Physical World (2027)
6. **Research Lab Principles**: Historical best practices trump modern organizational theory

---

*Sam Altman's perspective reveals OpenAI's evolution from research curiosity to defining the "core AI subscription" category, emphasizing adaptability and principled execution over detailed master planning.*