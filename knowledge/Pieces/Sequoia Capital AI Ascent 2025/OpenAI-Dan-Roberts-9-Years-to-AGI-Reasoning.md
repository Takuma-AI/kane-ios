# 9 Years to AGI? OpenAI's Dan Roberts on Reasoning and Emulating Einstein

**Speaker**: Dan Roberts, Research Scientist at OpenAI (formerly Sequoia Capital)  
**Event**: Sequoia AI Ascent 2025  
**Date**: May 8, 2025  
**Duration**: 10:10  
**Transcription Date**: August 23, 2025  
**URL**: https://youtube.com/watch?v=_rjD_2zn2JU

---

## Executive Summary

Dan Roberts, a former Sequoia team member turned OpenAI research scientist, presents OpenAI's breakthrough in test-time compute and reasoning models. He outlines a contrarian vision where reinforcement learning will dominate over pre-training, and makes a bold prediction that AI will achieve Einstein-level discoveries within 9 years.

## The Test-Time Compute Revolution

### Dual Scaling Discovery

**Train-Time vs Test-Time Compute**
> "The plot on the left said that the model improved when we trained it train time compute. This is something that everybody sort of who trains AI models is familiar with. The really exciting thing was this this plot on the right which said that the model improved also with test time compute. We we taught it to to uh reason and it would spend some time thinking and then the more time it spent thinking the more it would improve."

**Paradigm Shift Significance**
> "This is uh so important that we we put it on a t-shirt like this is this is like a totally new dimension for for scaling um that's not just training it's also you know at test time."

### O3 Reasoning Capabilities

**Physics Problem-Solving Performance**
Roberts demonstrates O3 solving quantum electrodynamics problems:
> "This is quantum electronamics. It can also see. So somebody poses a problem on that sheet of paper... it can think about things. It can iterate. It can zoom in... it gets the answer correct and it took about a minute to do that."

**Human Comparison Benchmark**
> "As a as an aside, a colleague asked me to before they put up this blog post to check this calculation and it took me about 3 hours, even though this calculation is in four textbooks that I have to track down everything that it did, make sure that all the minus signs were correct and verify that I got the right answer."

**Current Capabilities vs Future Goals**
> "We can do think for say a minute and and do some some pretty cool calculations... So our models think for a minute now and they can reproduce textbook calculations and and perturbations thereof but like we want them to like make major contributions to the state of human knowledge and science."

## The Einstein Thought Experiment

### The 8-Year Discovery Timeline

**Historical Context**
> "Let's imagine we go back to 1907 before he started working on general relativity. And we asked him the final exam question for general relativity... it would take him about eight years and to solve the problem or what I'm saying is that you know he would discover and this is what happened eight years later he discovered general relativity."

**Model Performance Comparison**
> "GPT 4.5 actually made this up, but I can verify that this is a a valid sort of question that you might ask... turns out GPD4.5 couldn't get this right answer. We needed 03. Uh, 03 was able to get it."

## The Contrarian Reinforcement Learning Thesis

### Inverting the Traditional Paradigm

**The Yann LeCun Cake Meme Challenge**
Roberts references LeCun's famous analogy:
> "This is a slide that Yan Lun made some some number of years ago I guess 2019... the point is that pre-training is like this big cake and reinforcement learning is supposed to be like this little cherry on top."

**OpenAI's Contrarian Vision**
> "This is where we're going. We want to we want to totally invert the meme here. Uh, uh, you know, we have like maybe the same size cake and we just want to crush it with a giant reinforcement learning cherry."

### Compute Evolution Timeline

**Historical Progression**
> "A year ago we put out GPT40. There was uh compute used and it was all pre-training compute and as you can imagine then we started doing this thing that led to test time compute. So we we added some reinforcement learning comput RL compute for 01... 03 maybe had a little bit more RL compute."

**Future Projection**
> "At some point in the future maybe we'll have a lot of RL compute and then at some far point in the future maybe we'll have just like be totally dominated and crushed by by RL compute and this so like this is this is I think is kind of a contrarian point of view like this is this is where we're going uh and we we mean it."

## OpenAI's Scaling Strategy

### The $500 Billion Plan

**Infrastructure Scaling**
> "What's our plan? Well, um, can't tell you our plan. I sent my slides in and uh, the comm's team just redacted the whole thing... you know what our plan is like like our plan I think we actually talk about it very clearly we're scaling compute."

**Concrete Implementation**
> "We're going to raise $500 billion we're going to buy some land in Abalene Texas build some buildings um put some computers inside... we're going to train models hopefully have a lot of revenue from that and then build some more buildings, put some more computers inside and so forth."

### Scaling Science Development

**GPT-4 Prediction Success**
> "This plot was from our GPD4 blog post... this dot down over here is the final loss performance of GPD4. These dots were experiments that they did along the way... this dotted line was the prediction. So, so they nailed the prediction, right? So, they they set out to train this model that's bigger than anything that anyone had ever seen and they knew exactly what it was going to do."

**New Paradigm Challenges**
> "Now that we have these new directions with test-time compute and and and um reinforcement learning training, we have to throw everything out the window and and reinvent what does it mean to apply um you know to scale up compute."

## Current Limitations and Challenges

### The "Idiot Savant" Problem

**Current State Assessment**
> "This is a point that uh podcaster dwares Patel made that our models right now they sort of feel like idiot zones. They they don't you know they're not they're not discovering general relativity."

### Potential Causes and Solutions

**Question Formulation Issue**
> "It's it could be that we're maybe just asking the wrong sorts of questions. A lot of things that we do in research is is about like, you know, the way the way in which you ask the question is more more important than the process and the answer. So, you know, we need to really get the question correct."

**Training Data Concerns**
> "Another another issue might be you could say is that we're training on too many competition math problems and and maybe our models are sort of like like jaggedly good at at different things."

**Scaling as the Solution**
> "But I I think really the thing that's going to happen here is that we're we're we're scaling up. Um, we need to scale this up further and and it's going to be really fantastic when we do."

## The 9-Year AGI Prediction

### Task Length Exponential Growth

**Current Trajectory**
> "This is an exponential growth in the length of tasks that agents can do AI or that AI can do. It's doubling every seven months. So looks like they according to this plot, they can do tasks that are about an hour. Maybe next year where will we be? They'll be about um two two and a half hours between two and three hours."

**Extrapolation Methodology**
> "It's it's dangerous to to make predictions in AI. Everyone's always wrong, but maybe maybe I can extrapolate a line here."

**The Einstein Timeline Calculation**
> "Where do we want we we're talking about this 8 years of Einstein and thinking and so eight years and and to to get there from now we need about 16 doubling times. So that means that like I guess the point is that in 9 years we're going to have a model that that will discover general relativity."

## Key Technical Insights

### Test-Time Compute Breakthrough
- Models can improve performance through extended reasoning time
- This creates a new dimension for scaling beyond just training compute
- O3 demonstrates practical quantum electrodynamics problem-solving in minutes

### Reinforcement Learning Dominance
- Traditional pre-training will be overshadowed by RL compute
- This represents a fundamental inversion of current AI training paradigms
- Scaling RL compute is key to breakthrough capabilities

### Reasoning Model Evolution
- O1 introduced basic test-time reasoning
- O3 demonstrates significantly enhanced reasoning capabilities
- Future models will scale RL compute dramatically

## Strategic Implications

### For AI Research
- Focus should shift from pure pre-training scale to RL optimization
- Question formulation becomes critical for breakthrough discoveries
- Scientific discovery applications represent the ultimate test of reasoning

### For Industry
- Massive compute infrastructure investments will be necessary
- The company achieving reasoning breakthroughs first gains significant advantage
- Traditional metrics of model capability may become obsolete

### For Timeline Predictions
- Current exponential growth in task completion length suggests rapid capability growth
- 16 doubling periods (at 7 months each) points to transformative capabilities by 2034
- Einstein-level scientific discovery represents the benchmark for true breakthrough

## Distinctive Terminology and Concepts

- **Test-Time Compute**: Computational resources used during inference for extended reasoning
- **Train-Time Compute**: Traditional computational resources used during model training
- **Idiot Savant Models**: Current AI systems that excel at specific tasks but lack breakthrough discovery capability
- **RL Compute Dominance**: Future paradigm where reinforcement learning overshadows pre-training
- **Scaling Science**: The discipline of predicting model performance at unprecedented scales
- **Einstein Timeline**: 8-year period representing the gold standard for transformative scientific discovery