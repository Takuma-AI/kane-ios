WEBVTT

1
00:00:00.020 --> 00:00:12.010
Chloe Lannert: This session is part of Techstar's sort of core curriculum. Thanks for the heads up, Vivian, and good luck at your pitch competition. You're going to kill it.

2
00:00:12.910 --> 00:00:17.259
Chloe Lannert: Part of Techstar's sort of core curriculum. So

3
00:00:17.580 --> 00:00:24.630
Chloe Lannert: there's there's a baseline level of understanding of some core concepts that techstars wants all their founders to have.

4
00:00:24.670 --> 00:00:49.140
Chloe Lannert: They've put this together by interviewing tons of program teams, tons of founders, figuring out what the key weak spots are, and putting together some core features that they want founders to have contact with early in the program. So we've made some edits, and we've adapted the core stuff a little bit. But this is pretty baseline. It's stuff we'll be coming back to throughout program and customizing a little bit more as we go on.

5
00:00:49.140 --> 00:01:00.009
Chloe Lannert: But we're going to kick it off with assumptions and experiments, which is a little bit of an iteration from our hypotheses and experiments. Sort of core workshop.

6
00:01:01.310 --> 00:01:03.849
Chloe Lannert: But yeah, Sylvia, you want to. You want to dive straight in.

7
00:01:03.850 --> 00:01:13.229
Sylvia Bouloutas: Yeah, definitely and just quickly. Is there anything cool you want to say about tomorrow or any of the meetings we have tomorrow? That'll be very tied in with the second part of this workshop. You guys. By the way.

8
00:01:13.390 --> 00:01:39.489
Chloe Lannert: Absolutely. If you have not submitted your goal. Setting packets, I pinged you about it yesterday. Please get those in and please schedule time as well with the team. This is a really great opportunity to service needs early in program and for us to signpost you to resources that are really going to help you hit the ground running. We're really excited to all. Get the chance to sit down with you, so if you haven't locked that in, please do so.

9
00:01:40.550 --> 00:01:41.250
Chloe Lannert: Thanks, Sylvia.

10
00:01:41.250 --> 00:01:57.100
Sylvia Bouloutas: Okay, yeah, great cool. And we'll talk a little bit more about like what okrs mean for our team. For you guys. In the second half of this workshop. But yeah, as Chloe said, so we're gonna start out with a workshop about assumptions and experiments. And you know, it's

11
00:01:57.180 --> 00:02:19.610
Sylvia Bouloutas: a lot of stuff that I think is such an important part of the accelerator and a huge skill to build kind of as a founder. So everyone can see the the presentation correct. Okay, cool. So, okay, this is a huge skill that we want you to to develop as a founder is kind of this. Really, you know, specific ability to separate assumptions from reality.

12
00:02:20.084 --> 00:02:38.259
Sylvia Bouloutas: And you know, every company is really built on a series of guesses. It's like who your customers are, how they're going to behave, and what will make them buy something. But really, you know, we've seen time and time again, it's so important to not just kind of guess blindly about these assumptions.

13
00:02:38.260 --> 00:02:58.450
Sylvia Bouloutas: and to kind of systematically test and refine what assumptions you are making about your customers about the market and about your product. So today, we're going to learn a little bit more about how to use this kind of assumption slash hypothesis driven thinking to kind of reduce risk and make smarter decisions, and ultimately just get the Pmf as fast as possible. So

14
00:02:59.281 --> 00:03:07.369
Sylvia Bouloutas: in overall, like, you know, we're really learning a skill today? So it, you know, in in the reality, is that a lot of startups

15
00:03:07.370 --> 00:03:32.210
Sylvia Bouloutas: that have challenges, whether it's getting off the ground or gaining more traction. It's not necessarily because of a bad team or execution, but it's because a lot of teams end up spending months or years, or even longer, you know, building something that their customers don't truly want. And this ties into like the Jdbt work we've been doing and are going to continue to do throughout program. But you know, our goal today is to really get you guys in a good spot about understanding these assumptions

16
00:03:32.560 --> 00:03:45.660
Sylvia Bouloutas: and the things that you believe that are true. But you haven't kind of deeply tested you know, with with your customers and with your products. So you know, if you think about it in a way, every every assumption you don't test

17
00:03:45.660 --> 00:04:06.319
Sylvia Bouloutas: is like a trap, essentially, that could really hurt your company, and our goal is to make sure that absolutely does not happen to you. And everything that you kind of test about your company is based on on facts. So I'd love to kind of start out with sort of an exercise, and we can take a minute to think about this. But is there something that

18
00:04:06.320 --> 00:04:12.229
Sylvia Bouloutas: you think right now that you believe about your company? But that hasn't actually been proven yet.

19
00:04:12.230 --> 00:04:33.209
Sylvia Bouloutas: and this could be something about your customers, your marketing strategy, even your pricing model right? And I mean, it could be. You know, I believe people will pay a premium for this specific coffee that tastes like lavender. It could be, you know, a lot of different kind of examples, right? But I'd love to hear, you know. Take a moment and hear any kind of hypothesis. You guys have.

20
00:04:35.180 --> 00:04:48.200
Chloe Lannert: For folks who have done the goal setting packet. Looking at your riskiest assumptions. Test that we had you do in. There is a great place to start key things that you're operating as if they're true. But you don't actually have validation yet.

21
00:04:49.480 --> 00:04:50.690
Ankur Toshniwal: Yeah, I mean, I'll.

22
00:04:50.990 --> 00:04:52.340
Sylvia Bouloutas: Yeah, yeah, yeah.

23
00:04:52.790 --> 00:05:08.040
Ankur Toshniwal: Oh, sure. Okay, cool. One. I mean, this is one that we we were talking about yesterday. And for originally we were thinking. Our assumption was that, like, you know, other products or other teams, big teams won't do what we're doing. But

24
00:05:08.040 --> 00:05:26.970
Ankur Toshniwal: the true hypothesis and the real risk is that the market that we're going into isn't big enough and isn't growing fast enough, that there isn't a place that we won't be able to vertically integrate and be able to solve a particular niche group's problem. And

25
00:05:26.970 --> 00:05:32.999
Ankur Toshniwal: you know, there were, basically, we're we're assuming that there's going to be a large enough

26
00:05:33.310 --> 00:05:57.539
Ankur Toshniwal: growth in the web data economy that even if other people get a little bit into the space, there's going to be even more that needs to be specialized in that we will always be able to find it, and that there isn't going to be like one winner amongst this entire market that's going to just completely dominate. And we're like shit out of luck. So, but that is an assumption, though. Yeah.

27
00:05:57.860 --> 00:05:59.030
Sylvia Bouloutas: Yeah, okay.

28
00:05:59.170 --> 00:06:08.369
Sylvia Bouloutas: that's a good one. Assumption about the market assumption, about the white space in the market assumption, about the opportunities in the market. Yeah, that's great. Does anyone have another assumption? They'd like to share.

29
00:06:08.370 --> 00:06:14.090
Chloe Lannert: Yeah, in the chat Jopnet shared. If we make a cool product, salespeople will adopt it easily.

30
00:06:14.380 --> 00:06:15.150
Sylvia Bouloutas: Oh, man!

31
00:06:15.150 --> 00:06:25.910
Chloe Lannert: Salespeople are looking for for tools and are willing to integrate tech into how they're currently interacting with customers. That's like a great example of an assumption that you're making.

32
00:06:26.130 --> 00:06:29.580
Sylvia Bouloutas: That's really good. Yeah. Would love to hear one more.

33
00:06:31.730 --> 00:06:33.010
Chloe Lannert: Yeshiva! Go ahead.

34
00:06:33.180 --> 00:06:40.189
Siva (Neural Defend): Yeah, yeah. So actually, actually, I joined very late. So this I post is about our company, right? Like what we are.

35
00:06:40.190 --> 00:06:40.830
Sylvia Bouloutas: Yes.

36
00:06:41.410 --> 00:06:51.460
Siva (Neural Defend): So in a neural defund, we, assuming that you know everybody identity is going to be, you know, anybody can create a defects and everybody identities on sake.

37
00:06:51.570 --> 00:07:01.470
Siva (Neural Defend): and we are kind of in a mission to detect these kind of frauds. And eventually we'll become one of the top identity product.

38
00:07:02.060 --> 00:07:10.649
Siva (Neural Defend): Maybe it's kind of antivirus moment for AI thing. So that's a hypothesis. You know, like we are having kind of

39
00:07:11.200 --> 00:07:12.499
Siva (Neural Defend): that, I want to share.

40
00:07:12.680 --> 00:07:14.660
Chloe Lannert: Yeah, that's almost a 2 parter that.

41
00:07:14.660 --> 00:07:15.260
Sylvia Bouloutas: And then.

42
00:07:15.260 --> 00:07:25.909
Chloe Lannert: Deepfake fraud will be a big enough problem, like a significant problem and will continue to grow, and that companies are willing to pay for specialized deepfake, detection.

43
00:07:26.780 --> 00:07:27.309
Chloe Lannert: love it.

44
00:07:27.310 --> 00:07:44.939
Sylvia Bouloutas: Yeah, these are great. Yeah, these are great thanks guys for sharing. I think you guys gave some awesome examples of hypotheses and assumptions. And you know, here's some more right? And it could be. You know that Facebook is the best channel, right? It could be around

45
00:07:44.940 --> 00:08:02.270
Sylvia Bouloutas: kind of, you know, believing that social media is the marketing is gonna kind of result in qualified leads. It could be that your customers live in a certain area or have a certain profile. Right? So and I think, you know, it's important to see what you know we can do to really test these hypotheses

46
00:08:02.320 --> 00:08:21.120
Sylvia Bouloutas: and and do based we can do based on these hypotheses. So in the next slide. Here is a kind of really understanding the before and after so you can have a really kind of simple simple framework here where? It's, you know, because you observe that individuals

47
00:08:21.120 --> 00:08:34.599
Sylvia Bouloutas: 45 to 60 use Facebook a lot and and our and our social media reports confirm this demographic. I believe that Facebook is the best channel. And therefore I'm going to do? XY, and Z.

48
00:08:34.600 --> 00:08:42.629
Sylvia Bouloutas: So you know. Do you see how this works? It's a very kind of logical way to kind of test assumptions before making you know these big.

49
00:08:42.659 --> 00:08:46.750
Sylvia Bouloutas: these big bets. So I do want to pause there and see if anyone has any questions

50
00:08:49.440 --> 00:08:59.989
Sylvia Bouloutas: great. So I'm sure you guys have all taken science classes at some point in your life, and if this reminds you of anything, it definitely reminds you of the scientific method. I was like a huge science nerd. So I've

51
00:09:00.030 --> 00:09:11.450
Sylvia Bouloutas: done this 7,000 times, and it's it's very similar, though, and I think it is around how you know you have this kind of because and then you have the observation.

52
00:09:11.450 --> 00:09:23.250
Sylvia Bouloutas: and then you believe that, and then you have your hypothesis, and then, therefore you're going to perform an experiment. So it could be. Another example could be because I observed that dog owners

53
00:09:23.250 --> 00:09:50.630
Sylvia Bouloutas: struggle, you know, with finding vet appointments. I believe that an AI chat bot like will reduce customer frustration, and I'll test it by a simple Mvp. Chatbot tracking engagement right? So that that's kind of the framework right? And I think we've seen time and time again. That like this is how we find the found, you know, successful founders in our program really think is that they're not really. They're not assuming. But they're following this framework, and they're able to

54
00:09:50.650 --> 00:09:55.129
Sylvia Bouloutas: validate all of their kind of assumptions about their business.

55
00:09:55.130 --> 00:10:20.800
Sylvia Bouloutas: So we can go a little further to just kind of understanding. You know what is an assumption? What is a hypothesis? Right? It's kind of a starting point. And that's the best way to think about it. It's not a conclusion. It's just a starting point. And it's okay to be wrong. I think that, you know founders put a lot of pressure on themselves to have such a good understanding of their business and their customers and their market. But the reality is that, like that, understanding only comes from a lot of different assumptions that you're making.

56
00:10:20.830 --> 00:10:33.679
Sylvia Bouloutas: and most of them are going to be wrong. And that's your job is not to be right all the time, but it's to figure out the truth faster than other people in the market, and faster than you were, you know, figuring out before, right? So

57
00:10:33.940 --> 00:10:53.750
Sylvia Bouloutas: we find that a strong hypothesis is testable. So you have to be able to run an experiment to verify the hypothesis is that it's precise. So it's specific enough to measure. It's not vague, it's very specific, and it's discrete. And what that means is you know, for any math people in here, too, it does it focus on kind of one variable at a time?

58
00:10:54.240 --> 00:11:20.109
Sylvia Bouloutas: So that's there's a number of different types of hypothesis, and they're not all created equal. They fall into, you know, usually 2 buckets, right? So there's like foundational hypotheses or assumptions. And these can really relate to your customer your problem. The market so it could be an example is, I believe, solo entrepreneurs value automation over price

59
00:11:20.110 --> 00:11:27.719
Sylvia Bouloutas: when choosing marketing tools. So this is a very foundational hypothesis. It's based on a foundational belief on your business.

60
00:11:27.780 --> 00:11:48.750
Sylvia Bouloutas: And then there's you know, functional hypothesis, right? Which is, they focus on specific parts of your business, right? Like your product, your pricing your sales, your hiring. So that could be something like, I believe free trials convert better than freemium for b 2 b Saas companies. So that's another hypothesis that you could have

61
00:11:49.111 --> 00:11:58.759
Sylvia Bouloutas: and you know, would love to think about like you know. What kind of hypotheses do you feel like? You know your your company needs to focus on right now?

62
00:11:59.660 --> 00:12:08.579
Sylvia Bouloutas: Love to hear a little bit more from the crowd, or any questions that you may have about the different types of hypotheses, and how they can be kind of categorized within these categories.

63
00:12:09.560 --> 00:12:32.240
Chloe Lannert: Yeah, here it can be really tempting to just trust your gut. And a lot of all of you have experience in your problem space which is part of why you were chosen. That connection to your market is really strong, and you're going to have a better gut feel than most do. But that openness to being wrong and commitment to

64
00:12:32.470 --> 00:12:58.110
Chloe Lannert: testing constantly, and iteration is something that's going to lead to long term success. I know I keep bringing up Jake. Just because you guys have familiarity with him. It's just the most obvious example. But he is constantly constantly running experiments to the point that the group he was trying to serve. He found out that that wasn't the best customer for his product during program, and totally shifted how he was approaching the product in general so.

65
00:12:58.680 --> 00:13:26.209
Chloe Lannert: Like. He was very wrong about some very fundamental assumptions in his business, and the humility to be wrong, test things out and move forward is really fundamental to why he is where he is, and this whole process is pretty nitty, gritty at the start. But this becomes a muscle. I'm sure many of you have your own shorthand on how you test things already, just trying to get the bones in a good spot here. Yeah, Japnet.

66
00:13:27.670 --> 00:13:56.419
Japnit Ahuja: Hi, sorry. I'll just try a stab at it. So I think, based on what you were saying, like observation. We when we were because we work at the dealerships, and we're at the dealerships. We noticed that sometimes it took customers like over 30 min to get matched to a vehicle, because the salesperson had to go to the manager so to get that approval for which vehicle. So we thought that, or the assumption we made was that if we give them a faster matching system which automates that process

67
00:13:56.820 --> 00:14:05.589
Japnit Ahuja: they will naturally gravitate towards it, and I think the hypothesis was that we give them a product that matches in seconds compared to like

68
00:14:06.060 --> 00:14:33.819
Japnit Ahuja: 20 min going to the manager in a line, they would use it. And I think now, a lot of the I don't know if it completely fits here. But maybe you guys can help me with that is like the experimentation we're doing is that because we pivoted from b 2 c to B, 2 B right, the flow of the product is very one question at a time. Let's make a profile because it was more online dating. But now we're realizing that sales people want to do it even faster. So we're like, you know, like we have been discussing this for a couple of days. It's very recent

69
00:14:34.180 --> 00:14:51.610
Japnit Ahuja: that we might want to make like a 1 page version of it, or put the contact information first, st maybe, or makes, and what something that we have been doing which has indicate has been indicating us that this is the direction they want to go into is because we've been removing some questions. We've been making a lot of questions optional which were mandatory before, based on their request.

70
00:14:51.610 --> 00:15:04.509
Japnit Ahuja: So like this is like some right now, I think we're experimenting on the product itself, so that we have higher usage from the salespeople, so that we make it so easy that they just use it more. Does that make sense.

71
00:15:05.460 --> 00:15:22.730
Chloe Lannert: Yes. Oh, yeah, yeah, okay. I love this. So this is like layers to this. So you're assuming that like in terms of assumptions, you're seeing that sales people like your. Why, your observation is that you're seeing that it takes salespeople a really long time to match customers with vehicles.

72
00:15:22.900 --> 00:15:42.160
Chloe Lannert: The assumption there is that that's the biggest part of the sales process that needs optimization. Assumption that the sales people themselves are going to be the ones using the solutions in a customer facing way, that it's not going to be the managers using the solution like that. I love that, Sylvia. I don't know if you want to dive deeper, but.

73
00:15:42.160 --> 00:15:51.269
Sylvia Bouloutas: No, that's that's a really really good example. And yeah, like, Chloe said, I think there's a lot of different parts of that. And there's almost like a lot of mini assumptions that you're making

74
00:15:51.330 --> 00:16:05.089
Sylvia Bouloutas: in between. And that's something super interesting that we can kind of go into, too, is that every assumption is like based on a lot of other smaller assumptions that get you there. But, as we said, kind of, you know right before that

75
00:16:05.100 --> 00:16:14.489
Sylvia Bouloutas: the best assumptions have those 3 variables that they're testable, precise, and discrete. So if your assumption, you know, is is a is very vague.

76
00:16:14.490 --> 00:16:39.160
Sylvia Bouloutas: I would do, and not that yours is. But I'm saying the you know, even if it's overarching, I would try, and you know, chat, use it as an as a challenge for myself to kind of go down and find a way to make it testable, to make it, you know. Precise. And yeah, to to be really easy to measure, and just with one variable to make it discrete. So but that that's

77
00:16:39.160 --> 00:16:43.249
Sylvia Bouloutas: that's super cool. Yeah, like.

78
00:16:43.250 --> 00:16:50.100
Chloe Lannert: That's that's great, because it relies really heavily on your experience experience and your intimate knowledge of the industry, like you only have the observation.

79
00:16:50.100 --> 00:16:50.850
Sylvia Bouloutas: Regions.

80
00:16:50.850 --> 00:16:55.759
Chloe Lannert: Information to go off of, because you're really involved with your customers, which is.

81
00:16:55.910 --> 00:16:56.420
Japnit Ahuja: Yeah.

82
00:16:56.970 --> 00:17:21.859
Japnit Ahuja: I think I I don't know if this is an experiment. But like one experiment we're planning to run is to like a very Mvp version is like, get the contact page first.st And the way we're gonna test it is to see if the usage increases cause it's something that we have noticed like, it's a very small feature change, I guess. And then the way that's the hypothesis would be like. Let's say we get the contact page first, st and the salesperson is able to capture the information quickly.

83
00:17:22.089 --> 00:17:29.780
Japnit Ahuja: Then maybe they'll use it more, because, like, it's easier now. So does that qualify as a more specific hypothesis.

84
00:17:30.520 --> 00:17:45.659
Chloe Lannert: Yeah, totally like with it, as a discrete experiment. Like the the format of your form. Whether contact details come 1st or not, whether questions are optional or not, like those are all great discrete variables to to take a look at.

85
00:17:47.430 --> 00:17:48.380
Sylvia Bouloutas: That's awesome.

86
00:17:48.710 --> 00:17:51.040
Sylvia Bouloutas: Anyone else have any comments or questions.

87
00:17:51.040 --> 00:17:56.120
Ankur Toshniwal: Well, so when it comes to kind of the year, I

88
00:17:56.290 --> 00:18:01.035
Ankur Toshniwal: totally makes sense that you want them to be like, discrete or testable.

89
00:18:01.510 --> 00:18:19.560
Ankur Toshniwal: What do you? How do you then reason about some of the like? The bigger ones like when I was the one that I mentioned like, I guess maybe, is the idea that, like through a lot of smaller hypotheses, you're able to make better conjecture about like the the larger one. Or you just like like, how do you? How do you test

90
00:18:20.570 --> 00:18:24.430
Ankur Toshniwal: that? A market is going to grow a certain way, or that.

91
00:18:24.550 --> 00:18:30.560
Ankur Toshniwal: you know? Like, I guess, how do we? How do we distill that like into.

92
00:18:30.980 --> 00:18:58.259
Chloe Lannert: So my my gut here goes to the idea of top down versus bottom up market analyses. I don't think you can realistically test whether a market is going to grow in the context of a startup. I think going bottom up and in terms of like immediate customer need is probably a more productive way to think about this context of, like the short term experiments, you're going to be running as you

93
00:18:58.450 --> 00:19:04.243
Chloe Lannert: like, grow to capture more market share. But having that fundamental

94
00:19:05.330 --> 00:19:16.040
Chloe Lannert: understanding of the uncertainty in in your business is is a good place to start in terms of larger, riskier assumptions. I don't know if that's helpful.

95
00:19:16.040 --> 00:19:42.190
Ankur Toshniwal: Yeah. So I mean, and if I'm derailing you, just tell me to stop. But I think what? Yes, like, we have like a lot of small experiments that we, I think I don't even know if we label them as experiments. It's just like kind of automatic. Where, like, you know, we assumed people would have Urls to crawl. And they were like, actually we don't. So we put in search and we got better. You know, traction from that. And then people are like, okay with search. Now, there's a whole bunch of duplicates.

96
00:19:42.190 --> 00:19:56.739
Ankur Toshniwal: And so we're like, okay, maybe we remove the duplicates. People like the results better. And so there's a lot of iteration in that process of experimentation. But it's still, I guess, through all of that it's still not clear.

97
00:19:57.119 --> 00:20:14.960
Ankur Toshniwal: You know that there's a larger market that we can kind of really penetrate. So how do we, I guess, like, is there a way to make the smaller experiments build on each other in a way that can lead to like more insightful kind of answers.

98
00:20:14.960 --> 00:20:28.700
Ankur Toshniwal: Even if we start small, I think that's totally fair, and that's really only the way to experiment it. But how do we structure the smaller experiments so that we can have better insight into like the direction of something, something that's like documentable.

99
00:20:28.990 --> 00:20:32.490
Ankur Toshniwal: Otherwise it's just all in our head. And it's really hard to like reason about it.

100
00:20:33.640 --> 00:20:58.610
Chloe Lannert: Yeah, my 1st thought is that you started out with proving out a niche, and this could even be through jobs to be done. You have your existing customers trying to validate whether that's a need at scale, or you happen to land some very specific people within a certain niche, proving those out is a really great place. To start in terms of validating a wider market jobs is

101
00:20:59.350 --> 00:21:25.200
Chloe Lannert: how we've traditionally done that in terms of understanding deeper customer needs, and figuring out, if you can service them, and in terms of experiments to validate the wider market, it could, it could be just examining further customer profiles through through jobs or other methods, and then building out a wider sort of understanding of your business roadmap and and vision. From there.

102
00:21:25.520 --> 00:21:35.459
Sylvia Bouloutas: Yeah. And just just to add to that, that's great. And I think this is a good example of like, okay, my market is growing. It's a difficult. It's a difficult assumption to test right? Because

103
00:21:35.460 --> 00:22:00.340
Sylvia Bouloutas: you can't always know what's going to happen in 5 years. And also it's not incredibly quantifiable. So I think that ways that you can sort of the assumption is like the market is growing, and then the hypotheses, you know, could be that like the tam, for industry is expanding by 15% right year over year, and then continue to go through a number of different data sources. Whether it's industry. Benchmarks, you know, kind of startup and Vc.

104
00:22:00.340 --> 00:22:00.970
Sylvia Bouloutas: Like.

105
00:22:00.970 --> 00:22:26.949
Sylvia Bouloutas: you know, newsletters and trends and seeing what like benchmarked industry like our similar companies are, you know how they're performing in the industry, and then add adding, those Jwd and customer demand signals right in. In addition to that competitive landscape work. Where you're able to kind of draw conclusions from those multiple sources. I think that's the best way. But again, like, I think, you know, getting as narrow as possible is the best way to like, go out and test the assumptions.

106
00:22:27.130 --> 00:22:44.109
Ankur Toshniwal: Yeah, makes sense, I would say for us, maybe one of the mistakes that we're making or one of the things we can improve on is, I think we naturally do a lot of this we already like, we're constantly on all the feeds we know, like what market things, but I think we're perhaps maybe not doing a good job of

107
00:22:44.470 --> 00:22:48.519
Ankur Toshniwal: structuring it in and writing it down every time, right like, in a way that.

108
00:22:48.520 --> 00:22:48.960
Sylvia Bouloutas: Yeah.

109
00:22:48.960 --> 00:22:58.190
Ankur Toshniwal: Okay. So then we can look back and like, Hey, here's there's too much in my head already. Let me like offload that. So maybe we'll try that.

110
00:22:58.190 --> 00:23:27.620
Sylvia Bouloutas: Yeah, and this this one here on this slide. And we're going to do a little exercise on this if we have time. But this here is a really good way to kind of almost write it down and be really scientific and methodical about. This is the observation that we've made about our product, our market, etc. This is a belief we have, and is it proven? Is it unproven? We can rank it, and then we can run some experiments on it. So this framework is something that we've seen founders use, and that has been really helpful.

111
00:23:29.270 --> 00:23:30.450
Sylvia Bouloutas: Yeah, Antoine.

112
00:23:32.890 --> 00:23:39.819
Antoine: Yeah, I mean listening to to this discussion. It feels to me that.

113
00:23:40.430 --> 00:23:55.879
Antoine: So there's there's hypotheses that are. I mean, I I would, I would just be extremely discriminating on the on the these like these, these

114
00:23:56.300 --> 00:24:03.579
Antoine: important, unproven hypotheses, and the whole, like the market, is growing.

115
00:24:03.910 --> 00:24:13.440
Antoine: or the market is growing by 50%, or whatever I would, I would actually dispute that it. I would totally say that it's unproven. I have no idea

116
00:24:13.580 --> 00:24:16.460
Antoine: I would totally dispute that it's high importance.

117
00:24:16.790 --> 00:24:21.790
Antoine: And for me, the really, the really, the crux of it is.

118
00:24:21.930 --> 00:24:28.359
Antoine: it's important because it's a big deal, etc. Obviously it's better. But at the end of the day.

119
00:24:28.480 --> 00:24:31.789
Antoine: if the market is shrinking, am I dead?

120
00:24:33.400 --> 00:24:39.060
Antoine: If I'm not dead, if the market is shrinking, it's probably that it's not that important

121
00:24:40.350 --> 00:24:42.629
Antoine: and and and.

122
00:24:42.630 --> 00:24:50.049
Ankur Toshniwal: I would definitely argue that all of our companies are dead if the markets are shrinking, that would be very bad.

123
00:24:50.050 --> 00:24:50.999
Antoine: And my and my.

124
00:24:51.000 --> 00:25:01.149
Ankur Toshniwal: Markets determine more than any one of us could want to say that they will, unfortunately, and there's only so much that's in our control. But I hear you.

125
00:25:01.600 --> 00:25:15.320
Antoine: Yeah. Yeah. And and I think that's that's I'm kind of a mindful of the fact that I am kind of going against a generally agreed

126
00:25:16.995 --> 00:25:28.299
Antoine: statement, etc. Core belief, etcetera. I would really encourage each of us for these unproven high importance hypotheses

127
00:25:28.450 --> 00:25:40.450
Antoine: that keep us awake at night, and that we don't have a strong. I would really encourage us to ask ourselves, Is it really does that matter that much?

128
00:25:40.560 --> 00:25:43.929
Antoine: And and and the the

129
00:25:44.500 --> 00:25:55.570
Antoine: so. So that's 1 1 thought I wanted to share. And again, I'm I'm not saying I'm right. I'm just saying that's kind of what's what comes to me. And the second thing I wanted to say to the point around like the the whole.

130
00:25:55.770 --> 00:25:59.509
Antoine: the the thing that Sylvia was saying like.

131
00:25:59.700 --> 00:26:04.829
Antoine: is it testable? If it's not testable, it's not useful.

132
00:26:05.110 --> 00:26:12.089
Antoine: That's the thing at the end of the day. And so so again, the market is growing. If you don't have a way to test it.

133
00:26:13.470 --> 00:26:32.800
Antoine: You don't. Yeah, I mean you. You can't do anything with it and and so so I think kind of just being super super rigorous on these things. At least, that's the way I kind of I I would. I'm I'm applying that to myself. And again, I'm not saying, I'm right. I'm just saying like, Hey.

134
00:26:33.310 --> 00:26:33.740
Chloe Lannert: Oh, that's.

135
00:26:33.740 --> 00:26:48.220
Antoine: And I would be happy to have a very long discussion about shrinking markets in which small startups explode, because explode in a positive sense, because I do have a bunch of counter examples.

136
00:26:48.780 --> 00:26:49.510
Chloe Lannert: Yeah, that's it.

137
00:26:49.510 --> 00:26:49.950
Sylvia Bouloutas: Yeah.

138
00:26:49.950 --> 00:27:05.689
Chloe Lannert: That's a great thanks for the perspective. We do want to keep things functional and actionable for the time being. Within the context of the program. And within the context of you guys being really lean teams who can test things out and change gears really quickly. The other

139
00:27:05.690 --> 00:27:20.280
Chloe Lannert: pretty fundamental thing to keep in mind is that you guys are pre seed. You can change so much, so fast you can change your your entire market, your entire product. You are in a position of flexibility. That, is, is

140
00:27:20.290 --> 00:27:31.529
Chloe Lannert: really really special. So letting yourself be totally dependent on market forces and and letting your work be totally dependent on market forces isn't

141
00:27:32.050 --> 00:27:39.600
Chloe Lannert: like that. Uncertainty is always there. Uncertainty is fundamental to startups, but I don't know that it's a deeply productive.

142
00:27:39.870 --> 00:27:40.279
Sylvia Bouloutas: Good evening.

143
00:27:40.280 --> 00:27:45.090
Chloe Lannert: About it at the moment. Because you have so much power to change.

144
00:27:45.220 --> 00:28:09.369
Sylvia Bouloutas: Yeah, I agree. And I love this discussion, though. And I really think we should talk about this like in person. Irl. Next week, at some some moment like whether or not a growing market like what that means for your business and etc. But what I will say is that there. There are things that are out of your control that you're gonna have to make assumptions about like, you can't always control these things. But I really think that for the purpose of this workshop, and just honestly, like advice

145
00:28:09.470 --> 00:28:19.939
Sylvia Bouloutas: for texture slash beyond. It's important. The more you can measure it, the more you have control over it, the more you can change it, and you can control your own destiny and control where the company goes. Because, I mean.

146
00:28:19.940 --> 00:28:44.279
Sylvia Bouloutas: who knows? Like, what's going to happen with the market? Who knows? Geopolitical challenges? Who knows the startup ecosystem is going to look like in 10 years, and even what venture. Capital firms are going to look like. But all you can do right now is focus on making assumptions that you can test, and that you can further your hypothesis. Further, your belief that this is a real problem for real people who are going to pay for it.

147
00:28:44.280 --> 00:28:57.239
Sylvia Bouloutas: And if you can just solidify that. That's all we want. That's what we want from you at tech starts, because we think that's gonna set you up to succeed. Moving on. So that's, you know, definitely, we do want to keep it. More.

148
00:28:57.440 --> 00:29:09.579
Sylvia Bouloutas: more focus. I mean, here's some more examples of hypotheses. These are great. By the way, assumptions that you guys have shared. This is awesome. This is, you know, just some kind of some broad ones like it could be around your products right? Like. I believe

149
00:29:10.350 --> 00:29:22.160
Sylvia Bouloutas: you know, majority of small business owners are seeking solutions. It could be even more niche stuff about your product like, oh, if you offer a light version of your software. It's gonna increase conversions by 20%.

150
00:29:22.557 --> 00:29:46.210
Sylvia Bouloutas: There's there's marketing hypothesis, whether it's different different marketing strategies, video content social media marketing. You know, these are all different, different. You know, assumptions. And then there's hiring right whether or not recruiting via slack or doing. You know, a recruiting software or going through universities is kind of the best way. And these are all really, the one thing to point out is these are

151
00:29:46.210 --> 00:30:15.049
Sylvia Bouloutas: really specific, and I think these on the slide could be even more specific. I would urge you to get as specific as possible, and these are testable and actionable. So that's definitely something, you know, we want to see and kind of going back to going back to this is that it was our kind of original example of kind of the Facebook. Right? Like we're looking at. That's the observation. This is my hypothesis. And each hypothesis is going to be based on observation. So what you observe in the past

152
00:30:15.050 --> 00:30:22.820
Sylvia Bouloutas: can explain why you believe something is true. And then, you know, you're able to kind of go from there and

153
00:30:22.890 --> 00:30:38.510
Sylvia Bouloutas: see if it's unproven or or proven yet, and then you can rank by importance, which we're going to talk about, and then discuss what experiments to conduct. So this is, you know, something I wanted to just give you guys some time, for I think we can just do like

154
00:30:38.610 --> 00:30:43.990
Sylvia Bouloutas: 5 min if you want, if everyone and then we're not gonna do like breakout rooms or anything. But

155
00:30:44.170 --> 00:30:56.040
Sylvia Bouloutas: if you guys want to share, I know some of you have shared your kind of assumptions and hypotheses in the in like the group. But if there's anyone who hasn't spoken with, if you can come up with a couple

156
00:30:56.190 --> 00:31:12.170
Sylvia Bouloutas: assumptions, hypotheses about your business things that you know you really believe to be true. It could be product market customers, operation. Just write a couple down right, and for each hypothesis write down the observation that led you to believe that hypothesis to be true.

157
00:31:12.170 --> 00:31:38.310
Sylvia Bouloutas: like, what did you see. What did you hear? What did you experience that really informed this belief? So really get to the root of you know why you have this hypothesis. So dig, dig deeper into like where this kind of came from, and then to know whether or not this hypothesis is proven or unproven. So if it's proven. Do you have data to back it up right? And that's kind of way one way to think about it. Like, have you run experiments on this?

158
00:31:38.647 --> 00:31:51.420
Sylvia Bouloutas: That someone else can conduct and come to the same conclusion like without your influence. So what that means is, are you? Have you been able to run like a proper experiment here that you can kind of rep someone else can replicate.

159
00:31:51.848 --> 00:32:02.359
Sylvia Bouloutas: So we know if there are any questions on this, let me know, but would love for everyone to take, you know, a couple of minutes. Write some stuff down, and then, when you're ready to to kind of to come up. Yeah. Yeah. Alex.

160
00:32:02.540 --> 00:32:11.390
Alex Nativelle: Yeah, I had a question about that, because a lot of like some of the assumptions we have in my mind are based on like studies

161
00:32:11.890 --> 00:32:26.989
Alex Nativelle: done by like Mckinsey, or, you know, studies you found on the Internet stuff like that. How do you compare that to us? Actually, you know, doing an experiment on our own testing. Talking with people is that like same quality, same weights

162
00:32:27.150 --> 00:32:30.219
Alex Nativelle: is one or the other having better weights

163
00:32:30.620 --> 00:32:32.810
Alex Nativelle: like, for I'm thinking about like

164
00:32:33.010 --> 00:32:48.740
Alex Nativelle: one of our hypotheses, like applications. Numbers have sold a lot like the numbers like more than 30% number of applicants per job description, something that we've heard, not tested so much, but heard and read.

165
00:32:49.150 --> 00:32:51.730
Alex Nativelle: So is it proven, not proven, you know.

166
00:32:52.840 --> 00:32:55.001
Sylvia Bouloutas: Yeah, I mean, I think that like

167
00:32:55.430 --> 00:33:22.679
Sylvia Bouloutas: to me, the best findings are the ones from like real world data that you're able to validate and challenge from your own. I think those that's a great like. I think the the Mckinsey thing is kind of great market research and a great kind of foundational knowledge of it, but I would still say, like to try and get a little bit more narrow about an assumption, about maybe something more specific to your product, or something that you've noticed in a way that your customers behave, or in a way that

168
00:33:22.941 --> 00:33:29.990
Sylvia Bouloutas: you know something that you feel like, you know, is really niche to what you're building, Chloe. I don't know if you have something to add.

169
00:33:32.420 --> 00:33:38.140
Sylvia Bouloutas: No, yeah. Does that help? We can talk about this offline, too. Yeah, it's it can be confusing. I think.

170
00:33:38.140 --> 00:33:38.760
Alex Nativelle: Well.

171
00:33:38.760 --> 00:33:39.610
Sylvia Bouloutas: Yeah.

172
00:33:39.610 --> 00:33:46.729
Alex Nativelle: What I gather from what you're saying is like those studies, or whatever are like great, because they prove something.

173
00:33:46.730 --> 00:33:47.380
Sylvia Bouloutas: Yes.

174
00:33:47.380 --> 00:34:00.109
Alex Nativelle: But they're too generic. And so if you want to apply this to your, you don't have an edge with these things, with those kind of things right? So if you want to have like an edge on something, then you have to do your own research.

175
00:34:00.110 --> 00:34:02.080
Sylvia Bouloutas: Yeah, exactly.

176
00:34:02.080 --> 00:34:02.640
Alex Nativelle: All right.

177
00:34:05.620 --> 00:34:24.349
Antoine: And just just to bring it back to one thing that was I think Neil was saying yesterday. It's the whole thing about like the average height versus the viability of the height, for the for in the plate, etc, the thing is the the the fallacy with the

178
00:34:24.560 --> 00:34:38.449
Antoine: I mean, we will always find a market segment that is growing in a shrinking market, or we will always find and to the extent that it's a market segment we're actually going after. It matters a lot

179
00:34:38.560 --> 00:34:52.329
Antoine: to the extent that it's a market segment that we are absolutely not going after, because, like it's we shouldn't care we, we couldn't care less. And the problem with this big like a market data is, they might be right

180
00:34:52.650 --> 00:34:53.230
Sylvia Bouloutas: Yeah.

181
00:34:53.551 --> 00:35:03.199
Antoine: But but they are hiding so much variability that it might be that our the little corner of the market that we're tackling is is actually behaving very, very differently.

182
00:35:03.550 --> 00:35:18.539
Sylvia Bouloutas: Yeah, yeah, that's really true. And honestly, just like this is not necessarily part of the workshop. But just because something you know, we've been thinking about. And I think about all the time I actually started my career as a founder, you guys. So I built a company. We can talk about this next week.

183
00:35:18.660 --> 00:35:40.850
Sylvia Bouloutas: and I think something that I did all the time is I would like fall in love with my own hypotheses, like I really wanted things to be true. I was like, this is true. But just because I wanted it to be true doesn't mean that it was. And I think that's really what we're trying to kind of drill in here is that that's a mistake. We see all the time where you're able to really get attached to kind of your own assumptions about

184
00:35:41.250 --> 00:35:59.769
Sylvia Bouloutas: your business, your customers, the industry you're in so you know, we're really just trying to like dissect that into quantifiable little nuggets that you can test, and that we can make it really. You know, like a process versus. Just keep it really theoretical.

185
00:36:00.307 --> 00:36:05.540
Sylvia Bouloutas: That. Yeah, if that some context here. But, Chloe, I saw you unmuted.

186
00:36:05.540 --> 00:36:09.650
Chloe Lannert: Yeah, all, with the goal of saving you time and money in the short term.

187
00:36:09.650 --> 00:36:10.030
Sylvia Bouloutas: Exactly.

188
00:36:10.030 --> 00:36:26.409
Chloe Lannert: The tech stars investment can disappear really quickly if you're throwing it down channels that you haven't proven out or tested. That's why this workshop is placed here right now to make sure you're making the most of your time. Effort and and cash in the short term.

189
00:36:28.390 --> 00:36:39.740
Sylvia Bouloutas: Cool. Alright. Does anyone have any other hypotheses or assumptions that they want to share, that they've made about their business? Someone, you know, maybe, who hasn't had a chance to to speak yet or speak up.

190
00:36:40.920 --> 00:36:45.270
Ankur Toshniwal: I was just gonna ask you, is the dock somewhere that we can grab? It is in base camp or something.

191
00:36:46.560 --> 00:36:48.859
Ankur Toshniwal: The Doc, for the hypothesis thing.

192
00:36:50.540 --> 00:37:00.059
Sylvia Bouloutas: There's no doc at this moment. I am gonna share this this afterwards, like I can share this afterwards, but for now is honestly just write down on a piece of paper like what assumptions you have.

193
00:37:03.820 --> 00:37:06.465
Chloe Lannert: Yeah, I'll do a timer for a couple more minutes.

194
00:37:07.490 --> 00:37:09.769
Chloe Lannert: we can look at this, and then we'll we'll circle back.

195
00:37:11.210 --> 00:37:11.810
Sylvia Bouloutas: Cool.

196
00:39:04.420 --> 00:39:06.649
Sylvia Bouloutas: Okay, one more minute. And then you guys

197
00:39:08.710 --> 00:39:16.299
Sylvia Bouloutas: gonna tell us some hypotheses. Don't overthink it. Just write down what you believe to be true, and observations that make you believe this.

198
00:40:10.570 --> 00:40:12.599
Sylvia Bouloutas: Okay, it is time.

199
00:40:14.590 --> 00:40:20.520
Sylvia Bouloutas: Good work, guys. Alright. So would love for someone to present.

200
00:40:21.480 --> 00:40:23.529
Chloe Lannert: I'm gonna I'm gonna pick on people who haven't.

201
00:40:23.530 --> 00:40:24.060
Sylvia Bouloutas: Oh, wow!

202
00:40:24.060 --> 00:40:27.879
Sylvia Bouloutas: But I can. Chris would love to hear from you guys.

203
00:40:30.110 --> 00:40:30.790
Chris Wong: Yeah,

204
00:40:31.800 --> 00:40:44.449
Chris Wong: so there's kind of like 2 hypotheses. One of them is, we believe, that most small and solo law firms seek an automated time tracking and invoicing product.

205
00:40:44.754 --> 00:41:13.569
Chris Wong: One of our initial observation was, or we had an initial hypothesis that was that they would prefer just a timekeeping solution, not an invoicing solution. And so we started to reach out to a lot of these like calls with these solo and small law firms. And we realized that the timekeeping pain point is not as strong as as if you were in a big law firm. So for that they would need something in addition to that which is like, we need you to track our time and be able to put it into an invoice and send it out. And so

206
00:41:13.580 --> 00:41:20.970
Chris Wong: that's why we have this new hypothesis. Now that we're trying to reach out and test this now with our our, the solo and small firms.

207
00:41:22.490 --> 00:41:29.110
Chris Wong: and so that's 1 another one that we're we've been trying to do is kind of gain traction with, oh, sorry! Go ahead.

208
00:41:29.110 --> 00:41:50.049
Chloe Lannert: Just to pause in there. It's also your experiment, like you're you're choosing small and solo law firms versus big law right off the bat. And I I understand why you're going for them first.st But you're looking at like their relationship with point solutions versus larger software suites like Super Super interesting. I'm I'm very, very excited to see how this continues to play out.

209
00:41:50.570 --> 00:42:07.480
Chris Wong: Right? Right? And yeah, another assumption that we were we initially had was, you know, going after the big law firms 1st versus the small law firms. And one thing we found out is that they have year long sales, processes, and need to find traction, and also they want to be able. They they oftentimes

210
00:42:08.020 --> 00:42:21.000
Chris Wong: see what other people are using. So and that helps bake in their confidence of using your software solution. So that's why we that was another hyposit. We ran that we validated and have moved on to this, and that's why we got to this new one.

211
00:42:22.440 --> 00:42:28.220
Chris Wong: Another one, a separate. One is more on like kind of growth and traction. Is that

212
00:42:28.830 --> 00:42:47.600
Chris Wong: It's it's generally pretty. We we've experienced a lot of difficulty in terms of reaching out to solo and small law firms, they see their time is very valuable. So what is their like? What's the point of them? Kind of reaching out to us and spending time to just like talk to us is like it's like, that's a that's a hurdle in itself. But through that hurdle we've come to we've

213
00:42:47.780 --> 00:43:17.029
Chris Wong: we initially tested out with email marketing and Linkedin Sales navigator, Linkedin sales Navigator being somewhat more successful. And through these calls we started to talk with lawyers and identified that the most the times that they adopt legal tech solutions is actually, when they go to these in the legal field. They call it Cles. But it's basically these learning sessions that you have to go to. And you have to do in order to get your license as a lawyer you have to go and learn things

214
00:43:17.030 --> 00:43:29.280
Chris Wong: every every year. So it's going to these events where it's live, and you're sitting in a room with other lawyers. And you're learning at these presentations that they are more open to like meeting other people networking, and through that also, like.

215
00:43:29.330 --> 00:43:55.819
Chris Wong: you know, adopt, like, and be more open to like getting to know who you are and and checking out your software. If you go to these Cles, which are like small event sessions all around, like different cities to like. Maintain your bar license. So that's something that we're testing, that we believe that that is true. But we haven't really gone out and done any of these Cles just yet, because we just learned about these over the past like month, we've identified 2 lawyers who mentioned this to us. So now we're on this like new trail. Yeah.

216
00:43:56.850 --> 00:43:57.360
Chloe Lannert: Love, that.

217
00:43:57.360 --> 00:44:18.649
Sylvia Bouloutas: That's awesome. I love that. And I love how your assumptions, hypotheses are also like logic based. I've noticed, you know, I feel like they really flow from. You know what you observed and kind of. You know what your assumption is, and you know, kind of where you are in the state. So it's super super helpful, and a really good kind of framework. So thank you for sharing, Chris. That's awesome.

218
00:44:18.650 --> 00:44:39.299
Chris Wong: 1 1 question we have is, how? How how much experimentation do we have to go to? To validate or UN like prove or unprove the the hypothesis, because, you know, given, we have limited information and limited amount of time to like to like kind of test. These fall out fully. But that's a question maybe we can answer later. But yeah, it's something that we we face. Yeah.

219
00:44:39.300 --> 00:44:59.969
Sylvia Bouloutas: Yeah. And I think there's no necessarily really right answer. And it's so vague it can be what you're testing, how much uncertainty exists and what we're going to talk about next, which is like how critical these assumptions are to your business right? And I think you don't have to test every assumption you have. But you know, you do have to focus on those kind of high risk assumptions versus low risk assumptions

220
00:45:00.020 --> 00:45:16.029
Sylvia Bouloutas: and focus on those kind of 20% of experiments that are going to give you like 80% of the learning, I think. But this is definitely something we should. We could talk about offline, too, and we can talk about it more. I'd love to hear from. I'd love to hear from Meg as well if you.

221
00:45:16.030 --> 00:45:16.420
Meg Hall: Yeah.

222
00:45:16.420 --> 00:45:18.060
Sylvia Bouloutas: If you'd like to share. Yeah.

223
00:45:18.060 --> 00:45:23.349
Meg Hall: Yeah, sure. So I kind of have some different things written written down. And I think

224
00:45:23.490 --> 00:45:29.010
Meg Hall: it's really illuminating like a big like issue that's kinda sticking out to me. If that makes sense.

225
00:45:30.256 --> 00:45:34.409
Meg Hall: So you know, the very 1st one is is like, you know.

226
00:45:34.520 --> 00:45:40.989
Meg Hall: sales reps. Want to be more thoughtful and strategic. Right like, do sales reps, want to be more thoughtful and strategic.

227
00:45:42.210 --> 00:46:05.860
Meg Hall: Like enterprise reps and strategic reps. Right? And then I you know the second one is, the sales managers want this. The reps to have a plan, right? So what happens every single year is a lot of times. You know, the sales managers will say, pick your top 10, and you need to like, make this account plan. And the rep has to fill in their whole entire. Go to market strategy. And I'm thinking, back to

228
00:46:05.860 --> 00:46:20.590
Meg Hall: the reps used to always complain about this because they felt like it was such a time suck right because they feel like they know it all in their head, and they have to put it into this like ugly, outdated slide, and present it back to their boss and stuff. And so I think we know that, like

229
00:46:21.030 --> 00:46:27.280
Meg Hall: the the managers wanting their reps to be more thoughtful and strategic is a hundred percent, I believe, is like, not really.

230
00:46:27.450 --> 00:46:37.969
Meg Hall: I don't think that's an issue. I think that's how we're getting the managers to come on board and pay for it very upfront. But I think that's also why we're struggling with, like some of the adoption issues, is like the

231
00:46:38.360 --> 00:46:55.899
Meg Hall: we're assuming that the the end user wants to be thoughtful and strategic. And there's some people who don't want to be thoughtful and strategic. And so maybe it's a matter of like it's I don't think that there's 1 way you can say. You know there's millions of sales reps in the world. You can't say in general all sales reps. Don't thought on strategic.

232
00:46:55.900 --> 00:46:56.320
Sylvia Bouloutas: Yes.

233
00:46:56.320 --> 00:47:01.089
Meg Hall: I think that maybe it's like, how do we identify who they are? Or you know.

234
00:47:01.330 --> 00:47:17.449
Meg Hall: I don't know. We need to figure out how to pick out who's going to be? Do that? And then also what's in it for the people who don't want to be thoughtful and strategic. So I don't even know if I came up with a hypothesis and a solution, but it definitely has me thinking and like writing down notes about it. But

235
00:47:17.650 --> 00:47:23.720
Meg Hall: I don't know. It's not necessarily like. Do reps. Want to be thoughtful and strategic is a very big, broad

236
00:47:24.030 --> 00:47:25.110
Meg Hall: thing to say.

237
00:47:25.110 --> 00:47:26.579
Sylvia Bouloutas: Yes, yeah. And I think.

238
00:47:26.580 --> 00:47:51.380
Ankur Toshniwal: Maybe just maybe a nice question could be to ask is, do they know how to be thoughtful and strategic? Maybe they want to be, but they don't know how to be and like it's like a hard. That's a hard thing to do. So maybe maybe assumption that might be a little bit easier to test might be. Do they know actually how to? I don't know. I don't know if it just reframes it a little bit.

239
00:47:51.940 --> 00:48:00.470
Chloe Lannert: Yeah, or even super simply the sales reps who want to be thoughtful and strategic, want to use tools to help them do so.

240
00:48:00.570 --> 00:48:23.729
Chloe Lannert: And I think jobs is going to be really interesting for you, looking at different salesperson profiles. Maybe it's people who are up for promotion in the next year. Maybe it's like any series of external factors that will help you define and qualify which salespeople are going to be your super users, and then you'll be able to continue to work through there and start with them.

241
00:48:23.820 --> 00:48:38.469
Chloe Lannert: And then, as you land larger deals and and are in a position where you have to engage with people who aren't necessarily like your core users. You'll be able to build out separate offerings and separate ways of interacting with them, to engage them with your product.

242
00:48:38.860 --> 00:48:39.990
Meg Hall: Yeah. Good, point.

243
00:48:41.080 --> 00:49:10.480
Sylvia Bouloutas: That's awesome. And I love this discussion. We have to continue. But one thing I really do love is that you guys are giving each other feedback and each other. Kind of you're thinking about each other's businesses, which is something amazing. And we'd love to continue to see that through the workshops and through the program so super grateful that you guys are so actively participating and listening to each other's assumptions. And you know questions about their business. So that's really how the cohort succeeds. So just moving quickly. Those are all great. What I mentioned before.

244
00:49:10.480 --> 00:49:12.570
Sylvia Bouloutas: We're gonna have high, medium, low

245
00:49:12.670 --> 00:49:37.850
Sylvia Bouloutas: assumptions, right? Like some of them are going to be critical to your business. Some of them are not business changing, and you know. Something of high importance, in my opinion could be like, oh, you know, people are going to pay $50 a month for a product, because if this is not right, like your pricing model fails. Something medium could be like. Oh, I think people, you know, between 25 and 35 years older users, I mean, if it's slightly off, you can always adjust right? And I think

246
00:49:37.850 --> 00:50:02.679
Sylvia Bouloutas: something low, important at some point some people like prefer like blue, like, I don't know text on my website versus red like. It's not going to really impact the business. So I will urge you. We're not going to do this now. But to kind of rank those hypothesis that in those assumptions that you wrote out just now, and you can do that kind of on your own. You can do it with your teammates. You can even post in base camp like message each other in base camp if you want, or post them on the, on the.

247
00:50:02.680 --> 00:50:13.229
Sylvia Bouloutas: in the in the chat and say, Hey, like these are the ones we had, and asked the group for feedback. This is how we're ranking them. These are some of the assumptions we're making about our business so definitely

248
00:50:13.230 --> 00:50:15.458
Sylvia Bouloutas: kind of engaged there. I think.

249
00:50:16.170 --> 00:50:20.229
Sylvia Bouloutas: as we dive deeper like, I think it's important. If

250
00:50:20.290 --> 00:50:49.760
Sylvia Bouloutas: you pressure test these assumptions like. For if it's proven like, why do I think it's proven? What data do I have that it's proven in? Is this data strong enough, right like. And I think for any sort of unproven hypothesis you're gonna say, why haven't I proven this yet? Why is it still unproven. What data am I missing to prove this? And where are our biggest gaps? So you know, an example could be. You know, users are gonna pay for our product if we have a free trial.

251
00:50:50.090 --> 00:51:11.190
Sylvia Bouloutas: And is this proven? Well, not really, because if we don't have enough paid users yet, it's not, it's not necessarily proven. So the missing data that you're going to need for this example is conversion rates from those free trials to the paid plans like that's just kind of a very broad example of ways to understand and pressure. Test

252
00:51:11.721 --> 00:51:17.980
Sylvia Bouloutas: your assumptions around like, whether they're proven or unproven. And I think

253
00:51:17.980 --> 00:51:45.970
Sylvia Bouloutas: unproven assumptions kind of, you know, based on kind of what I was saying before. It's like you want to see how to challenge your own assumptions right like. And if it's unproven, it's usually because you haven't tested it. It's usually because you don't have enough data. And it's usually because it's something you're assuming, but you honestly don't know. So you know what's missing, and we'll talk about a B testing more. But you know, I think a B testing for this particular example, it's about investing in social media marketing will result in more qualified leads.

254
00:51:46.298 --> 00:52:05.710
Sylvia Bouloutas: Versus email marketing and it's not proven because there's we don't have enough data to you know, kind of understand the effectiveness. So what we do need is that comprehensive data between the 2 different marketing campaigns. And I'm sure you guys have, you know, read a lot about marketing campaigns, and some of you have marketing backgrounds, too. So

255
00:52:06.020 --> 00:52:13.409
Sylvia Bouloutas: this is nothing too new. But it is important to like what's missing is you're gonna run those Ap tests. You're gonna do some lead quality analysis.

256
00:52:13.410 --> 00:52:36.779
Sylvia Bouloutas: Be a channel, you know, kind of the cost per acquisition like comparison. And you know, fundamentally, honestly, like the lesson I want you guys to take out of this is if you can't prove it with data, it is just an assumption. So really pushing you to prove everything you can with data and with kind of experimentation. So I think this is, you know, something to think about is

257
00:52:36.850 --> 00:52:55.060
Sylvia Bouloutas: but this is something we see at techstars. Also, it's like, if you've already made an investment like in something and you have a lot of biases towards it. And that could be like, Oh, I've invested so much time, so much energy, so much research on this space on this area. And you're able to have you're able to have these, you know.

258
00:52:55.490 --> 00:53:16.130
Sylvia Bouloutas: big biases towards that hypothesis or towards that assumption. But you know I would really urge you to pause on any sort of big bets on unproven assumptions for the next 3 months. Like while you're at tech stores and really lean towards backing every hypothesis and every decision you make with a lot of data.

259
00:53:16.594 --> 00:53:44.590
Sylvia Bouloutas: And I think that's what we've seen as the most successful founders at techsars. And you know after is that they really ask themselves like, am I biased towards this belief because it's something that I've been working on for a long time, or have invested a lot of resources in. Have I truly looked at this data? And am I trying to prove that I'm right like, is it an internal thing that I'm just trying to prove that I believe this is right? And I'm right, or am I actually just testing out the market to find out the truth?

260
00:53:45.132 --> 00:53:50.780
Sylvia Bouloutas: So this is huge. And I do want to pause there in case you guys have questions about this, because

261
00:53:51.120 --> 00:54:01.580
Sylvia Bouloutas: I can speak for myself. This is something I've done many, many times, and you don't even realize you're doing it sometimes that you have these small biases towards beliefs about your business or about the market.

262
00:54:08.620 --> 00:54:37.350
Sylvia Bouloutas: But the good news here is that if you realize your assumption is weak like you don't have the data to back back it up. You don't. You have gaps, etc? That's a good thing, because then you're able to really kind of approach this like a scientist, right? And be able to like on like, go through a process and go through kind of that reality, check and test. You know, to see, to kind of uncover the truth. Right? So this is what I was saying is, do you have any sort of?

263
00:54:37.430 --> 00:54:51.740
Sylvia Bouloutas: Is it reflection? Have you taken other perspectives? Do you have past hypotheses? And have they been different? And you know, have you looked at all areas of the business. And is this an outcome that you just want to believe is true?

264
00:54:51.830 --> 00:55:19.319
Sylvia Bouloutas: So here's another kind of exercise for you to do on your own time as well, is where you're going to pair up with someone else from the group. And again, I'd encourage you guys to do this on Base Camp, and you're welcome to not even pair up, but just to post your thoughts in the chat. But is there a hypothesis that you think is unproven. Has there been any observations led towards each hypothesis? And is there any data that you're missing? So really, pressure chest and challenge each other's?

265
00:55:19.380 --> 00:55:35.959
Sylvia Bouloutas: You know hypotheses. And not only on basecamp, not only today throughout the program, like, I want you to be able to get coffee with another cohort member, and they're going to tell you something, and you're going to be thinking, do they have assumptions to back? This is this something that they can prove?

266
00:55:36.342 --> 00:55:52.170
Sylvia Bouloutas: And is this something? Is there some way I can help them kind of see these gaps and push them to make every decision with data. So really, something I want to hold you guys to for yourselves, and also for your for your teammates and cohort mates, you know, throughout the next couple months. So

267
00:55:52.980 --> 00:56:03.990
Sylvia Bouloutas: I think, going quickly here. I think we're we're, I think it's important, you know, as a next step, to really think about these hypothesis and turn them into experiments.

268
00:56:04.100 --> 00:56:11.459
Sylvia Bouloutas: so a good experiment will answer like, what actions will you take? I will test this by XY. And Z.

269
00:56:11.710 --> 00:56:16.630
Sylvia Bouloutas: And you know what evidence will prove or disprove this.

270
00:56:16.890 --> 00:56:19.799
Sylvia Bouloutas: We will know if this is true, if

271
00:56:20.070 --> 00:56:27.100
Sylvia Bouloutas: you know. So it could be something like Facebook ads convert better than email marketing.

272
00:56:27.370 --> 00:56:34.059
Sylvia Bouloutas: And the experiment is to run identical ad campaigns, right for email marketing and Facebook ads for 2 weeks.

273
00:56:34.180 --> 00:56:40.090
Sylvia Bouloutas: So the evidence that you're going to get is going to be. You're going to compare the cost per conversion and the lead quality.

274
00:56:40.240 --> 00:56:54.839
Sylvia Bouloutas: So that's how we kind of frame it. And again, like this is so based on science. And essentially, you feel like you're sort of in a lab which you are. And I think that's really cool and exciting because you're able to like, I said before, kind of get to get to the truth. So

275
00:56:55.010 --> 00:57:08.350
Sylvia Bouloutas: there's there's a bunch of different kind of, you know, design experiments that I'd say that you can look at like, you know, I mentioned this before. And would love to hear. If anyone has experience using kind of these, there's

276
00:57:08.440 --> 00:57:25.760
Sylvia Bouloutas: kind of traditional A B testing where you're able to compare like 2 versions of a web page or other designs, just to see which one's getting the most kind of user engagement or conversion. There's something more concierge, right? Which can skew more consulting. But it's still in kind of

277
00:57:25.820 --> 00:57:38.600
Sylvia Bouloutas: it's still part of your business where you're able to provide a more manual service, to understand customer needs and gather insights before you invest all that time and energy on developing the automated solution. And then.

278
00:57:38.830 --> 00:58:06.520
Sylvia Bouloutas: obviously, there's Wizard of Oz, which is just, you know, basically someone's gonna buy it. And then you're just going to manually fulfill it. And this could be an example of like, oh, you want to match mentors and students right? And you're manually kind of, you know, matching them after someone you know, with the Google sheets, or something we've seen that happen to just to kind of prove out initial hypotheses about the business. And some of you might be, you know, later late, you know a little. Your businesses might be a little bit late for for any of these experiments. But

279
00:58:06.520 --> 00:58:15.390
Sylvia Bouloutas: yeah, I would love to pause and see if you guys have had any experience using any of these 3 or other experiments that you use to test your hypotheses.

280
00:58:19.450 --> 00:58:34.260
Chloe Lannert: I'll jump in and share some examples of how alumni have used these models. So for the concierge service, one of our hiring platforms from Oakland Spring 24.

281
00:58:34.260 --> 00:58:59.260
Chloe Lannert: As they were building out their matching algorithm, they were using, like expert interviewers to prescreen candidates for recruiters when they got new recruiters and companies on board, they would manually scrape applicants from different services, and they would Linkedin cold outreach to find expert interviewers, hire them on as contractors to conduct those interviews

282
00:58:59.260 --> 00:59:20.280
Chloe Lannert: before they got to critical mass on the platform for it to run automatically for the Wizard of Oz sort of methodology. We had a company that was doing a platform for collecting user feedback on video games, and they would run manual like they would manually scrape

283
00:59:20.700 --> 00:59:30.469
Chloe Lannert: tons and tons of data off of each gaming company's like reddits, discords, feedback boards, and they would

284
00:59:30.470 --> 00:59:56.439
Chloe Lannert: put that together as a singular report, doing everything on the back end Wizard of Oz style, instead of having the platform ready because they were still validating out whether the data that they were pulling from was useful enough for the gaming companies to pay for it. So people paid for these reports that were done totally manually without the product itself, and they were able to use that as validation that they needed to do the full product. Build

285
00:59:57.710 --> 01:00:01.459
Chloe Lannert: anyone else, have experience doing stuff like this.

286
01:00:01.930 --> 01:00:06.169
Chloe Lannert: Really, I feel like, you guys are doing a little bit of this like stuff that doesn't scale

287
01:00:06.290 --> 01:00:07.420
Chloe Lannert: back end.

288
01:00:11.372 --> 01:00:29.820
Anthony De Silva: Yeah, I think in our marketing we we take that approach where we are like going knocking on doors and and trying to like reach out to people like we have phone calls or like going to open houses. But I, yeah, this, like, I've learned this concept. But it's like. It's not something that we've really implemented.

289
01:00:30.020 --> 01:00:30.450
Chloe Lannert: Okay.

290
01:00:30.745 --> 01:00:47.599
Anthony De Silva: Yeah. I think, too, like we were just having a discussion of like we think it in our mind. We think it's factual like times. If if we tell a client, hey, we're gonna save you time and money like, who wouldn't say yes. Like to the overall like idea of what we're trying to do.

291
01:00:48.176 --> 01:00:54.239
Anthony De Silva: But then I was like bringing. There's there's could be some complications, you know, if we are

292
01:00:54.860 --> 01:01:03.270
Anthony De Silva: incorporating like prices, like repair prices into our valuation models like it? Will it

293
01:01:03.430 --> 01:01:09.959
Anthony De Silva: reduce the overall appraisal value of a property? And like, how are people going to react to that? That's something that we need to test.

294
01:01:11.103 --> 01:01:17.310
Anthony De Silva: Yeah, I think we might need some help around like designing that test. Yeah.

295
01:01:17.880 --> 01:01:22.170
Anthony De Silva: not sure how like how we should do it.

296
01:01:22.550 --> 01:01:26.060
Anthony De Silva: Yeah, we we can talk offline. We'll make it happen.

297
01:01:30.750 --> 01:01:49.370
Sylvia Bouloutas: Great. The next slide is really just back to that framework that we've been talking about, you know, for the workshop. So you've got your observations. You have your hypotheses, so it's something you observe. It's the what you believe, then we can, as we kind of learned about. We can say whether it's proven or unproven.

298
01:01:49.580 --> 01:01:54.529
Sylvia Bouloutas: you rank it by importance. So, and then you can kind of run ads

299
01:01:54.650 --> 01:02:16.589
Sylvia Bouloutas: as an experiment for this example. But it could be a lot of different right like examples that experiments that you can run and I, I think this is like just a good framework to have and to continue to almost have like a log, right like, have like a list of things. You're observing hypotheses. You're building track. How important they are to the business, whether they're proven.

300
01:02:16.590 --> 01:02:32.720
Sylvia Bouloutas: whether they're unproven. And you know what that really means. For, like the kind of experimentation strategy for your business. So I think that's like where we'll end. It's kind of just more of an introduction. And again, these are things that we're going to be talking about so much throughout program and

301
01:02:32.740 --> 01:02:46.079
Sylvia Bouloutas: stuff more, just to get you in the frame of mind of constantly testing what you and like double checking yourself for things that you believe to be true. And I really want you guys to think like that. I want you to think like that

302
01:02:46.120 --> 01:03:01.970
Sylvia Bouloutas: starting today at noon, like I want you to start thinking like that every you know as often as you can, because that's going to continually give this like loop of just You know, building based off data. And that's what we really want to see. So

303
01:03:02.190 --> 01:03:18.689
Sylvia Bouloutas: I do want to like, pause here for a minute. Let's take like a 5 min break, guys. We'll be back at 11 to Npt. Everyone, you know. Take a minute. We're going to go into our next workshop after but yeah, any any other questions, you know. Put them in the chat, and we can try and get them try and get to them later.

304
01:03:19.110 --> 01:03:46.739
Chloe Lannert: Yeah, last little bit of emphasis. This sort of mindset is particularly important, because techstars is a pretty singular opportunity to get an incredible amount of feedback from your cohort, from mentors, from the team. So you have the opportunity to do a lot of testing and get a ton of feedback and opinions and data

305
01:03:46.760 --> 01:03:56.119
Chloe Lannert: to land in a better spot at the end. So I'll let's call it a bio break. Now I'll pause the recording, and we'll be back at 10.

306
01:03:58.970 --> 01:04:00.700
Chloe Lannert: Hit play on the recording.

307
01:04:00.700 --> 01:04:10.639
Sylvia Bouloutas: Thank you, Chloe. All right, everybody. Come back. Get started. Let's see your faces. So something to note. Here, we're going to talk about Okayrs. Kpis.

308
01:04:10.966 --> 01:04:28.459
Sylvia Bouloutas: we have. You know, those calls tomorrow, as Chloe mentioned earlier, this ties into that like, we want you to understand really closely what an Okayr is, so that when you're meeting with our team you're in a really good place to kind of define your vision. The milestones where you want your company to go and

309
01:04:28.460 --> 01:04:47.270
Sylvia Bouloutas: what you want out of Taxarse. So I would just say, this is important in regarding the meetings tomorrow. And then, Kpis, we're going to touch on briefly. But we're gonna have a whole presentation about that next week. So you know, definitely feel like more more to come about about this material. So let's start out. Okay, so what are the differences between

310
01:04:47.270 --> 01:04:49.930
Sylvia Bouloutas: okrs and kpis?

311
01:04:50.120 --> 01:04:53.609
Sylvia Bouloutas: I would love for someone to try and take a stab at it

312
01:04:54.510 --> 01:04:56.980
Sylvia Bouloutas: because they can seem similar. But they're different.

313
01:05:02.920 --> 01:05:03.479
Trina Das: No, I.

314
01:05:03.480 --> 01:05:05.070
Sylvia Bouloutas: Okay. I'm gonna sorry.

315
01:05:05.070 --> 01:05:05.869
Chloe Lannert: You to jump in.

316
01:05:05.870 --> 01:05:06.810
Sylvia Bouloutas: Yeah.

317
01:05:07.780 --> 01:05:30.360
Trina Das: So I think Kpis are. Basically, I think we'll start with Kpi, like Kpis are matrices to track, like, you know, different things that we care about in our business. And Okr is about like, you know, how do we actually reach those? Like, you know, metrics, goals by giving specific responsibility to certain team members

318
01:05:30.650 --> 01:05:34.330
Trina Das: and tracking them over time, or like a

319
01:05:34.700 --> 01:05:59.559
Trina Das: single point, responsibility for each of those Kpis and sub kpis, so that and also, like, you know, arranging the Kpi in a way that you know, there's an overall company goal, and then, like, you know, tracking it down to prod, like, you know, different kpis for like product, marketing sales and whatever. So that's the difference.

320
01:06:00.520 --> 01:06:07.100
Sylvia Bouloutas: That's great. Yeah, that's awesome. And I think that's very, very, very close to basically our definition. You know, if

321
01:06:07.470 --> 01:06:11.250
Sylvia Bouloutas: you know the way that we think about it is that you know.

322
01:06:11.440 --> 01:06:27.720
Sylvia Bouloutas: kp, Okr is to find where you want to go. So they're really high level, right? Like, it's a vision of the company. It's the milestones that you need to get there. The Kpis measure kind of the health of the company. They measure how you're getting there. It's performance tracking right? So.

323
01:06:27.810 --> 01:06:48.629
Sylvia Bouloutas: But they're very tied together, because in my mind, like you know, a Kpi, an Okr without a Kpi is just a wish like there's no way for you to track that product project or the progress. Sorry, it's just a wish, right? It's really theoretical. So and then a Kpi without an Okr.

324
01:06:48.760 --> 01:07:13.000
Sylvia Bouloutas: It lacks direction. It's just a number without a purpose, and we'll go into this more. But here's a super super simple example, okrs are the vision. They're the milestones. Here's an objective like to run faster than you know, 99% of the population. That's a crazy objective. I've this is definitely not my slide, you guys, I would never put that as a objective for me personally.

325
01:07:13.000 --> 01:07:20.900
Sylvia Bouloutas: But here is a key result to that objective would be to like run a marathon in 2.5 h, and

326
01:07:21.420 --> 01:07:28.470
Sylvia Bouloutas: the Kpi that you're using to track that is, track minutes per mile. So are you hitting your pace?

327
01:07:28.510 --> 01:07:52.580
Sylvia Bouloutas: So I I hope that makes sense. And you know you should think about your Okrs as a destination, and that the kpis are like a speedometer, right like. And I think in terms of a business. An example that I can use here is like a big Okr would be like growing revenue by 50% in the 1st quarter. Right? Like, it's huge, it's large, it's larger than life. And it's a big number. And

328
01:07:52.580 --> 01:07:59.310
Sylvia Bouloutas: and the key result there, like, how are you going to do that is getting to hit a million dollars in new sales this quarter?

329
01:07:59.310 --> 01:08:15.249
Sylvia Bouloutas: Right? And so so that makes sense. That's really tied together. And then the Kpi that you're measuring is monthly revenue growth rate. So that's just something standard. And it's simply something that you're just tracking the health of your company, tracking the the the progress. So

330
01:08:15.772 --> 01:08:44.650
Sylvia Bouloutas: you know, as we kind of mentioned right like these are, you know, okrs are those kind of, you know, objectives and key results. That's what okay stands for objective, what you want to achieve big goal key results. How you measure success. So specific targets? So you know, Okrs really force you to define success in a way that's measurable, which we love and you know, another example of an objective could be to improve user engagement.

331
01:08:45.109 --> 01:08:55.219
Sylvia Bouloutas: Right? Like, it's large. It's kind of, you know, it's big. And then a key result could be to, you know, in increase daily active users by 25 in 3 months.

332
01:08:55.220 --> 01:09:20.189
Sylvia Bouloutas: So you know, the key result is a little bit more kind of nuanced. And why use okrs? So you know, we think that you know, Okrs are incredibly helpful, especially at techstars. And hopefully, you can, you have been using Okrs, and you'll continue to use them in the future. I mean, they create really good focus with your business and with your with the company. They create accountability right and clear targets make it really obvious. If you're winning and encourages really big thinking. So.

333
01:09:20.189 --> 01:09:27.430
Sylvia Bouloutas: So you know, I I. And we'll talk about this. But Okr should always push you past your comfort zones

334
01:09:27.430 --> 01:09:48.342
Sylvia Bouloutas: right? Like, I think it should be like, okayrs are so ambitious that you're not going to hit 100 completion. That's not the point. They're always supposed to stretch yourselves and kind of see how far you know you can go so here's the great chart here on. You know how to kind of set these okrs. So we're gonna

335
01:09:48.680 --> 01:09:58.660
Sylvia Bouloutas: outlines the structure. So the objectives are going to be. They're going to be ambitious. They're going to be qualitative. Okay? So they're qualitative. And they're going to be very inspirational.

336
01:09:58.750 --> 01:10:19.899
Sylvia Bouloutas: And the key results. Those are very, you know, quantifiable time bound and outcome. Focus right? And then kind of below that, you're gonna see, you have a number of tasks, and those are, you know, the specific initiatives that are required in order for those key results to to take place. So

337
01:10:20.291 --> 01:10:25.539
Sylvia Bouloutas: you know, moving from there, and what I said before, and they're meant to be incredibly ambitious. Like.

338
01:10:26.060 --> 01:10:55.700
Sylvia Bouloutas: if you hit a hundred percent of your cares, you absolutely are not doing it right, like the sweet spot is actually 60 to 70 completion. Because for us it's like not reaching, it means that you're learning, and you're able to continually refine. You want to push your team to, you know, think beyond what they think is possible. And I think it's really encouraging. It's really inspirational kind of like I mentioned before. It's very ambitious. And I think it it it. It should be something

339
01:10:55.700 --> 01:11:03.350
Sylvia Bouloutas: very, very far reaching that really is like sets, you guys on a path. And so here are some kind of examples of

340
01:11:03.350 --> 01:11:31.059
Sylvia Bouloutas: kind of okrs that you can use in pro in program, right? So here's a specific one around product, where it's like you can supercharge product use. And then the key result is going to be increased daily usage of a product by 30 in 3 months. There's some sales okrs around nailing and validating Icp, and the way that you're measuring that right? With your key result is to attain 10 committed product pilots.

341
01:11:32.220 --> 01:11:58.990
Sylvia Bouloutas: You know. There's another objective convert. All users who trial like like. Think about that. Like all users who trial like it's impossible, right? But at the same time, like the key result is to increase trial to paid conversion by 15. So it's like, how are you gonna measure that? And I think again, your Okrs should be very kind of ambitious, and, you know, make but make sure at the same time that they can be measured through those key results.

342
01:11:59.650 --> 01:12:00.700
Sylvia Bouloutas: So

343
01:12:01.580 --> 01:12:29.009
Sylvia Bouloutas: there's this kind of optional Okr tracker. That you know we could use. I mean, I recommend. You probably do like 12 because we have a 13 week program here. So you're able to kind of use this this doc as a sample way to track kind of your okrs, in terms of the key result, the target result, the actual result. And then any gaps or lessons learned. And I think this is a great framework.

344
01:12:29.656 --> 01:12:35.380
Sylvia Bouloutas: To continue to define and kind of narrow down those okrs.

345
01:12:35.880 --> 01:12:42.490
Sylvia Bouloutas: So I would say that, you know, be consistent about setting that weekly milestone and share with the group

346
01:12:42.580 --> 01:13:05.929
Sylvia Bouloutas: for accountability. I think that's I think that's huge. So being able to really share with your team and share with your colleagues. Share with, you know, friends in the cohort share with kind of yeah, with your internal teams and with the program team around kind of what milestones you are tracking. And this is something, though, that, like I said, we're having those meetings next week, right? And

347
01:13:06.250 --> 01:13:29.810
Sylvia Bouloutas: a lot of those are going to be around or sorry tomorrow, and a lot of those are going to be around like, what are you tracking? And this is not something you have to come up like by yourself in a vacuum like you have to give us direction, but like we are going to be like playing ping pong with you with like, making sure you're getting the right okrs. Those key results. You're measuring the right kpis. And like these are things that I know that you guys are looking at measuring because I've

348
01:13:29.810 --> 01:13:48.040
Sylvia Bouloutas: read all of your applications. And you guys went through a long process to get in here, and I know it's stuff you're actively thinking about. So our job is now just to continue to refine that and make sure you're really measuring the health of your business in the right way, in addition to setting those kind of large okrs. And but, you know, setting tasks each week to achieve them.

349
01:13:50.010 --> 01:13:51.929
Sylvia Bouloutas: So okay, cool. So

350
01:13:53.240 --> 01:13:58.500
Sylvia Bouloutas: I'd love if you guys could, you know, again, make this a little interactive would love to hear

351
01:13:58.550 --> 01:14:11.609
Sylvia Bouloutas: you guys put into action right like, if there's any okrs you want to share with the group. It could be, you know. Write down a couple of kind of key objectives that you aim to achieve it. You know it could be something.

352
01:14:11.630 --> 01:14:40.410
Sylvia Bouloutas: you know. That you want to do throughout this month. It could be just throughout kind of the program and for each objective I'd really enjoy and like, encourage you to have like specific key results that are really quantifiable and measurable. So just to as a reminder. Objectives are those big picture goals that push the company forward, and then the key results are how you measure success. So only okrs, nothing. Kpis yet. So I'll just give you a really quick a quick example here is like

353
01:14:40.450 --> 01:14:53.600
Sylvia Bouloutas: you have to in inc. An objective could be like increase customer engagement. And then that key result is going to be boost daily active users by 25 in 3 months. So the key result is really

354
01:14:53.680 --> 01:15:08.160
Sylvia Bouloutas: specific. And then the objective is a little bit larger. So just want to pause any questions there. If you guys have any questions about kind of what you know how to define your okrs and then give you guys a couple of minutes to come up with some okrs and hear from the group.

355
01:15:17.430 --> 01:15:24.060
Sylvia Bouloutas: No questions. Okay, cool. Well, I'm here, Chloe, do you want to set a timer for like 5 min.

356
01:15:24.230 --> 01:15:31.110
Sylvia Bouloutas: and then we can. Yeah, we'll sync back in 5 min, and then a couple of you will present ideally people. We haven't

357
01:15:31.250 --> 01:15:34.520
Sylvia Bouloutas: heard too much from today. But it can be anybody.

358
01:19:51.860 --> 01:19:54.319
Sylvia Bouloutas: Okay, Chloe, how much more time!

359
01:19:55.730 --> 01:19:57.550
Chloe Lannert: About like 30 seconds left.

360
01:19:57.670 --> 01:20:01.939
Sylvia Bouloutas: Alright! 30 seconds. Guys wrap up your thoughts, wrap up your okrs.

361
01:20:04.100 --> 01:20:06.040
Sylvia Bouloutas: and then we'll share them with the group.

362
01:20:26.220 --> 01:20:28.409
Chloe Lannert: Alright! Alright! Let's bring it back.

363
01:20:28.790 --> 01:20:43.790
Chloe Lannert: This is something we'll continue to iterate over the course of program and something we'll keep coming back to in mid program, and we'll we'll continue to check in on where you stand with these okrs. But for now let's hear the results of the brainstorm.

364
01:20:53.380 --> 01:20:56.749
Sylvia Bouloutas: Alright someone volunteer, or else Chloe's gonna pick on you.

365
01:21:00.100 --> 01:21:01.840
Chloe Lannert: Optifab? Where are we at.

366
01:21:01.840 --> 01:21:02.580
Sylvia Bouloutas: Yeah.

367
01:21:02.580 --> 01:21:03.420
Chloe Lannert: Aria.

368
01:21:03.820 --> 01:21:04.740
Paria: Yeah, sure.

369
01:21:05.440 --> 01:21:29.369
Paria: So when it comes to objective, as you know, our companies in advanced manufacturing, like working with 3D printer manufacturers or Cnc. And other manufacturers. So one of the objectives which we think is we are aiming to achieve is like trying to. 1st of all, we aim to have 10 plus fully like

370
01:21:29.370 --> 01:21:36.624
Paria: fully paying manufacturers from aerospace sector. So that would be something that we're gonna aim for that objective in the beginning.

371
01:21:37.010 --> 01:21:39.530
Paria: And then the results which we

372
01:21:40.510 --> 01:22:08.405
Paria: expect, or the the results that we can expect from this objective. So by having these adopters of our product in these sectors and making a trust in the manufacturing community. We can penetrate to other industry sectors like automotive or like medical sectors, because this is a solution which can be applied to any manufacturer like in a wide range of industry sectors so and we can

373
01:22:09.030 --> 01:22:37.976
Paria: what else we can do by reaching these objectives if we can. If we can. I mean, achieve this objective. Of course, we can like work on our team, expanding our team also like enhancing the like. The other features of our product. For example, our products at the current stage is close loop software, which is working in the like offline mode. But if we can

374
01:22:38.560 --> 01:23:04.019
Paria: by like, by having like manufacturers to work with us so definitely, we can also add features like real time real time features. I mean real time control features of our product. This is something that I think as a result, it can happen in our product after like penetrating in a like or pro, having a good progress in the like. In manufacturing sector.

375
01:23:05.020 --> 01:23:24.829
Sylvia Bouloutas: Awesome. Okay, can I? Let me give you some feedback on that? That's great. Thank you for sharing, and I think that I think that it's great, and I think we can even improve it with a little bit more refinement. the objective, I think, is perfect, secure 10 plus aerospace manufacturers as an adopt adapter of your tech.

376
01:23:24.970 --> 01:23:44.880
Sylvia Bouloutas: Amazing. That's a great kind of objective. And it's it's big. It's high reaching. But you know, it's definitely kind of still specific. So the key results. I would urge you to refine them even more right where it is around. So you know, one key result for that could be signed contracts with, you know.

377
01:23:45.490 --> 01:23:56.549
Sylvia Bouloutas: 10 aerospace manufacturers or pilot agreements. Right? The second could be then financial right? It could be generate X amount in revenue from those deals within

378
01:23:56.990 --> 01:24:23.489
Sylvia Bouloutas: 3 months like, build a timeframe right? Get really specific, like, how much revenue do you want to see from those contracts, or from those pilot agreements. And what is the kind of timeframe? And then, when it comes to the adjacent industries, I would urge you to say things like expand into adjacent industries. But how many like 1, 2. By securing how many non aerospace customers like 2 aerospace customers and be specific like expand into

379
01:24:23.490 --> 01:24:50.600
Sylvia Bouloutas: one, you know, and then you can even kind of continue to go down that one right like where it's expanded to the industries. And those industries will generate X amount in revenue in only defense or only automotive. Right? I think you can get even more granular. But I think that's a really really great place to start, and I think with a little bit refinement, you can have that measurable success. So I think the outcome makes sense. But just having those actionable insights and measurable success.

380
01:24:50.630 --> 01:25:01.340
Sylvia Bouloutas: It's just gonna make you even stronger. But I think that's amazing. It's a really really good good place to start, and I think it's a super well thought out kind of strategic, I think goal.

381
01:25:01.580 --> 01:25:26.349
Paria: Thank you. Yeah. As you said, I mean, what what I got from your points here, Sylvia. So we have to be like in terms of like measure, like the metrics we have to be specific like this is the amount of like, for example, a medical manufacturer company which I wanna like achieve by going to this, by by pro by moving in this pass, right? Having the numbers as well in the plan.

382
01:25:27.240 --> 01:25:44.379
Sylvia Bouloutas: Yeah, that's my advice. That would be my advice. Be really specific, like, if you look at the slide like the objectives are those aspirational learnings. And then the key results are time based. They're financial. They're specific. There's a lot of numbers in each key result. I want to see numbers. I want to see how many contracts I want to see.

383
01:25:44.680 --> 01:26:05.420
Sylvia Bouloutas: You know whether it's revenue. I want to see dates, time, frames, month, the word month, and what worth the word days like? I think you want to see kind of numbers and all those bullets. I think that can make it even stronger, because the reason I say that is because then, if you look on this chart, the the tasks right, those initiatives required to drive progress.

384
01:26:05.890 --> 01:26:16.159
Sylvia Bouloutas: it makes it easier to outline what tasks you have to do if you have those really specific numerical kind of results tied to the objectives.

385
01:26:16.540 --> 01:26:19.569
Paria: Yeah, that makes clear. Thank you so much for the feedback soon.

386
01:26:19.570 --> 01:26:28.019
Sylvia Bouloutas: Of course. Yeah, of course. And we're going to go through this one on one with each of you, so you can escape. You can't escape building. Good. Okay. Ours here at techstars.

387
01:26:29.050 --> 01:26:31.680
Sylvia Bouloutas: So who's next?

388
01:26:35.500 --> 01:26:36.165
Sylvia Bouloutas: Chloe.

389
01:26:39.261 --> 01:26:42.579
Chloe Lannert: Alex, I don't think we've heard from you in a bit.

390
01:26:44.440 --> 01:26:45.490
Alex Nativelle: Yeah, sure.

391
01:26:45.730 --> 01:26:56.379
Alex Nativelle: let me pull up the thing. So one of our key objective is to learn qualitative and competitive insights on our customers

392
01:26:56.890 --> 01:27:01.389
Alex Nativelle: and so on, that we have a few key results.

393
01:27:01.980 --> 01:27:02.860
Alex Nativelle: But

394
01:27:04.200 --> 01:27:11.780
Alex Nativelle: yeah, some of those are not like one of the key results is have talked with at least 5 high value prospects in the Us.

395
01:27:11.920 --> 01:27:13.809
Alex Nativelle: Within the 1st month.

396
01:27:16.250 --> 01:27:22.210
Alex Nativelle: So that would be like one of the key results of that objective

397
01:27:22.560 --> 01:27:32.060
Alex Nativelle: and then other key results is, have a clear picture of our target market in the Us. For the current offering, broken down by relevant segments.

398
01:27:34.900 --> 01:27:39.930
Alex Nativelle: So that's kind of like 2, the 2 cube is there like, yeah.

399
01:27:40.170 --> 01:27:43.639
Sylvia Bouloutas: Yeah, yeah, to. That's great. I think that's awesome. Is it?

400
01:27:44.140 --> 01:27:48.090
Sylvia Bouloutas: Very good, I think, in order to kind of improve it for that, I'd say

401
01:27:48.428 --> 01:28:12.789
Sylvia Bouloutas: you know, I think again your objective is good. I think you're able to. You want to refine it more. You can say, you know, into customer needs pain points right? Their decision making process. You're just trying to gain insights into those specific areas. And then the key results is conduct those 5 customer interviews within. What did you say the 1st month? Yeah, the 1st month, and then you can even go down from there is.

402
01:28:12.820 --> 01:28:36.089
Sylvia Bouloutas: you know, maybe from those customer interviews like identify 3 common recurring themes from those conversations or and then kind of capture like act 2. Actionable, like takeaways that influence maybe one part of your business that you are really kind of thinking about a lot, whether it could be product pricing or go to market. So that way you're able to

403
01:28:36.100 --> 01:28:45.269
Sylvia Bouloutas: get real insights from those conversations and kind of dive deeper into the measurable progress. And like the learning outcomes that you're gonna have.

404
01:28:46.470 --> 01:28:48.579
Alex Nativelle: Okay. Well, yeah, alright.

405
01:28:51.490 --> 01:28:53.439
Alex Nativelle: Can't think to go that deep. Yeah.

406
01:28:53.680 --> 01:29:02.830
Sylvia Bouloutas: Yeah, no, I think the the deeper you go, because the more specific your key results are. Then, like I said, the better your tasks can be, you know, as you look at

407
01:29:03.430 --> 01:29:07.320
Sylvia Bouloutas: as you look at your your tasks, I think. Let's

408
01:29:07.460 --> 01:29:27.330
Sylvia Bouloutas: let's continue with the presentation, for now, because I do want to let you guys off on time. And then we're going to talk about these okrs and key results and tasks one on one tomorrow slash throughout the program. And I'm literally always here. I love doing this. You can always message me about it. But let's I do want to give you

409
01:29:27.883 --> 01:29:50.079
Sylvia Bouloutas: a little bit of a sneak peek on Kpis, because we're gonna do this next week. In person. But I I think it's important that you have foundational knowledge on this because it really is like the heartbeat of your business. And you know, like, I think there's there's different ways to, you know. Measure kpis, like

410
01:29:50.170 --> 01:30:14.680
Sylvia Bouloutas: as an from the more investment standpoint. Like, you know, you don't look at a payments process pay or a Payments company right? Like the same as you would look at a marketplace like you're measuring Gmv. For one for the other one. Maybe you're measuring like transaction volume. So it is definitely kind of important to narrow down the key performance indicators for your business, for your business model for your industry, and like how you measure success.

411
01:30:14.780 --> 01:30:36.179
Sylvia Bouloutas: So okrs, I think, are really goal driven. But Kpis are really kind of ongoing metrics. So it doesn't really change, regardless of what your goal is, you sort of have. You know, the similar kpis across that measure sort of the health of health of your company. So you know, strong kpis. You know, they're usually clear. They're objective. They track

412
01:30:36.270 --> 01:30:47.732
Sylvia Bouloutas: and efficiency. They track performance. They show an impact. And they can really help decision making. So I think you know? There's then we can kind of take a take a look at

413
01:30:48.230 --> 01:30:58.229
Sylvia Bouloutas: You know what? What are the principles of kpis, and really how to pick pick the right kpis, and I think, like it's important to follow these principles when looking like

414
01:30:58.370 --> 01:31:04.630
Sylvia Bouloutas: they should be actionable over vanity metrics. So you know, raise of hand. Who knows what a what a vanity metric is?

415
01:31:04.880 --> 01:31:14.650
Sylvia Bouloutas: This is something you know, we talk a lot about. Yeah. And we we talk a lot about with our founders. So we want to make sure that we're actually tracking what really drives decisions. So

416
01:31:14.922 --> 01:31:35.049
Sylvia Bouloutas: it's really important to look at like total downloads, for instance, like may not show the whole picture right like daily crash reports, though, might show a lot more, because, even if like A to. You have total downloads like a lot of total downloads. It doesn't mean that the users are using the product or engaging with it in a way that's helping you grow. So I I it's important that it's not.

417
01:31:35.220 --> 01:31:46.599
Sylvia Bouloutas: And I think people make this mistake, especially as you guys go into like fundraising, you know, eventually, and we work together to kind of refine. That is, you want to be tracking the right things, to put your best foot forward in front of investors. And

418
01:31:46.710 --> 01:32:14.899
Sylvia Bouloutas: the way to get there is to really do this kind of analysis of your business versus like looking at. Yeah, like just saying that you have total downloads. It's easy to kind of poke holes there, but you want to make sure you do right doing kpis that can actually like support that you're, you know, support the stage of your business. So like you, you want them to kind of have flow over cumulative metrics. You're looking at trends over time, right? Because that's a little bit more specific. And that's gonna help. You kind of narrowly identify any problems.

419
01:32:15.290 --> 01:32:32.149
Sylvia Bouloutas: And I think it's important is like, as we said before, like the only way to get better is to identify like what what's not going well. And that's really like huge point of the workshop today. Right? Is that like, it's not so much about like, Oh, we want your business to be perfect. We just want it to be better like it doesn't have, you know, even if you have like

420
01:32:32.150 --> 01:32:48.005
Sylvia Bouloutas: you can. You know, it's not about having a million downloads. It's not about having the most impressive like these big, large numbers. It's about knowing where the problems are and how to solve those. And then that's the foundation that you continue to go off to build something highly successful. So

421
01:32:48.650 --> 01:33:06.749
Sylvia Bouloutas: you know, we want to do. Look at trends over time leading over lagging right? Like we want to focus on what predicts success so like, oh, you know, we had all these kind of you know, Demos Demos booked, predicts that future kind of revenue future revenue better than revenue close. So you do want to see? Kind of.

422
01:33:07.380 --> 01:33:27.820
Sylvia Bouloutas: I think we we do want to see kind of leading indicators. Obviously, you also have to include lagging, but something to be tracking, and then causation over correlation like, does it really impact growth? Right? And I think this one can get kind of lofty and theoretical. But you know it's you want to make sure that everything that you're tracking is actually connected. And honestly like

423
01:33:27.900 --> 01:33:56.690
Sylvia Bouloutas: these are just some principles, but real, realistically like, if a Kpi doesn't help you make a decision, then you really shouldn't be tracking it like you only need to track things are helping because you're gonna have. You know, you meet your team. You're gonna say, how can we? How can we figure out what to test. Next, how can we figure out? Should we launch another product to the market? Okay, this isn't working. We need to pivot. And you have to look at those Kpis to back you up like we said in the last presentation with data. So that's really kind of the fundamental thing here. And we can look at some

424
01:33:56.950 --> 01:33:59.859
Sylvia Bouloutas: examples by business function, too. So, like.

425
01:34:00.290 --> 01:34:26.390
Sylvia Bouloutas: you know, there's we have. Sorry we have, like, kind of Ltv, right? We have conversion rates. Nps could be interesting like if you're if you're in sales right like, it's like b 2 b could be like the weekly close deals. It could be like pipeline size. Right? It could be you know, sign up or sales meetings, close sales. It could be custom sign ups. It could be booked revenue. Repeat, purchase rate like.

426
01:34:26.390 --> 01:34:36.189
Sylvia Bouloutas: and it could be fundraising. Kpis, right? Something I'll work on with you guys is like, how many investor meetings do you have like, you know, like how many pitch deck use are you getting, or

427
01:34:36.190 --> 01:34:49.889
Sylvia Bouloutas: or deck fees? Are you getting in warm intro, so like this is something. We'll work with you to like, help. You refine what's the right one for your business model, and, like every business model, is so different, and you should all be measuring some of the same things, and then some of the some things that are not the same.

428
01:34:50.690 --> 01:35:01.170
Sylvia Bouloutas: So see so questions to ask for feedback. So when you're reviewing your kpis or your

429
01:35:01.340 --> 01:35:30.870
Sylvia Bouloutas: cohort, mates, kpis, right? I think it's important to share your kpis with people in the cohort, too, and bounce each other and bounce ideas off right like, hey? Like, do you think my kpis are the right ones for my business, whether to me, Chloe, Neil, or just to each other. Right? You want to look to see. What is it driving your business forward? Are these ambitious enough? Are they broad? Are they specific? And are they realistically achievable? So I think, you know, like, for instance, and this is again something to refine. But

430
01:35:31.690 --> 01:35:53.641
Sylvia Bouloutas: a Kpi, I'll hear, is like, Oh, I have a Kpi like, I want to increase my website traffic. But how do you know that like that, traffic is gonna necessarily convert into sales. And is there another way to convert into sales that you should be measuring? So really make sure it's tied to kind of real outcomes? So this is something

431
01:35:54.350 --> 01:36:12.219
Sylvia Bouloutas: you know, to to look at, and this is something you can take with you, and again, like post on base camp and stuff as you kind of look at what are the top? 3 objectives and which ones is going to have the most kind of significant impact? And why is it high priority? So that's what we talked about in the 1st half of the workshop and

432
01:36:12.840 --> 01:36:27.850
Sylvia Bouloutas: what Kpi is going to tell you the status of that objective. So that's different from key results. That's just how you're going to achieve the objective. But the Kpi is actually you know, specific measured progress like towards the Kpi. So it could be.

433
01:36:27.970 --> 01:36:34.059
Sylvia Bouloutas: It could be, for instance, like one of your Okayrs, could be increased trial to paid conversion.

434
01:36:34.718 --> 01:36:39.399
Sylvia Bouloutas: And then your Kpi is to improve that conversion rate.

435
01:36:39.590 --> 01:36:52.210
Sylvia Bouloutas: the trial to paid conversion rate from 10% to 15% in 3 months. So I do want to kind of pause there and see if anyone has any questions. And, Chloe, I know you unmuted yourself. If you have any anything to add.

436
01:36:52.830 --> 01:37:13.690
Chloe Lannert: Yeah, we're gonna be diving a lot deeper into Kpis in week one. And then, as we continue to move through program, it's something we'll be talking about a lot and iterating on a lot. I just want to double tap on the fact that that kpis are fluid and are another thing that's gonna change as your business changes stages.

437
01:37:13.690 --> 01:37:23.179
Chloe Lannert: even during program, people will switch up what they're measuring, depending on their goals and what what the key focus is. So this will be an ongoing conversation.

438
01:37:23.240 --> 01:37:33.180
Chloe Lannert: and you'll get lots of feedback on if you're landing in the right spot. If you're measuring the right things. But what we're really aiming to do here is give you a language to describe your progress over time.

439
01:37:36.060 --> 01:38:04.079
Sylvia Bouloutas: That's great. Chloe, yeah. And I think, like, it is important to just consistently ask yourself, like, How can you unlock the most in your business. But I actually would really encourage you guys to hop on basecamp or vox, and and you know, try and try and get feedback from one another, both about assumptions you have about your business, both about kind of okrs. And if you know, if you want, even, you can start to think about some kpis, and just really think about like.

440
01:38:05.220 --> 01:38:25.229
Sylvia Bouloutas: you know, what are some objectives that we're having, and you know what what kpis should? Am I measuring there and like Chloe said. Of course they're gonna change, but it's more just that you're you're like in tune with what your business needs. It's like the heartbeat of your business. A lot of the kpis. You have to be really in tune. With what specific are you measuring?

441
01:38:26.040 --> 01:38:31.020
Sylvia Bouloutas: Okay, I want to open it up for questions, because I went through this one a little quicker, because we were short on time.

442
01:38:40.000 --> 01:38:46.700
Chloe Lannert: Right. I expect to see some beautiful, beautiful Okr submissions like on founder room next week.

443
01:38:46.860 --> 01:38:47.620
Sylvia Bouloutas: You wanna see it?

444
01:38:47.620 --> 01:38:49.480
Chloe Lannert: Going to be incredible.

445
01:38:50.002 --> 01:38:57.760
Chloe Lannert: We were going to give you a lot of chances to sort of keep each other accountable, and cheerlead each other on

446
01:38:58.150 --> 01:39:00.119
Chloe Lannert: like in our physical space. So.

447
01:39:00.870 --> 01:39:11.129
Chloe Lannert: Excited to to see you all. If there's no questions on the workshop like any other questions about program, everyone feeling good about week. One, understand the calendar, have access to everything they need.

448
01:39:14.826 --> 01:39:15.420
Paria: I,

449
01:39:15.550 --> 01:39:28.399
Paria: yeah, I have. A quick question is for tomorrow's meeting that we have. It's about like the pro from 12. I mean the Gnp showcase. So I wasn't sure about. What is this? Can you a little bit like, talk about.

450
01:39:28.400 --> 01:39:29.380
Chloe Lannert: Yeah, yes.

451
01:39:29.380 --> 01:39:44.720
Chloe Lannert: absolutely so. In the pre-program updates, you should have gotten along with the many, many attachments a deck that introduces you to some of the partners that we have at techstars. So the Gmp. Showcase is a chance to meet those folks face to face.

452
01:39:44.720 --> 01:40:06.070
Chloe Lannert: Our Google reps. Our Amazon reps all the people at all the companies who are providing you discounts and resources. I think the style is traditionally breakouts, where different reps will like go into separate rooms. They'll have their little presentation sales pitch, whatever. But you'll get a chance to meet with people face to face and

453
01:40:06.120 --> 01:40:10.790
Chloe Lannert: chat a little bit about your individual situation and get a touch point about how they can help you.

454
01:40:11.266 --> 01:40:22.320
Chloe Lannert: There's more information in the deck about who those folks are, but that's your chance to get connected early with with some of the people you'll be communicating with throughout program.

455
01:40:23.290 --> 01:40:25.800
Paria: Oh, that's nice! Thank you so much, Claude.

456
01:40:26.610 --> 01:40:27.540
Chloe Lannert: Yeah. Anthony.

457
01:40:27.880 --> 01:40:36.690
Anthony De Silva: Yeah, for the goal setting portion tomorrow. Are we just joining the time that we're we have scheduled? Or should we? Okay.

458
01:40:36.690 --> 01:40:42.220
Chloe Lannert: You. Just you just join the half hour. Calendly. Link that's that's all we need you for during that block.

459
01:40:42.220 --> 01:40:43.240
Anthony De Silva: Okay. Awesome.

460
01:40:46.530 --> 01:40:47.330
Chloe Lannert: Awesome.

461
01:40:48.920 --> 01:40:55.170
Chloe Lannert: beautiful. Well, I'll see you all tomorrow. Please grab time on that calendly if you haven't already. And

462
01:40:56.310 --> 01:40:58.870
Chloe Lannert: Thanks for thanks for a good session.

463
01:40:58.870 --> 01:41:17.880
Sylvia Bouloutas: Yeah, thanks, guys. And thanks for everyone who shared, I know, like some of it is like, I threw a lot at you in like 2 h, and it was also like some sort of it, can feel a little theoretical. It can feel a little vague like these definitions and these processes. But as we work together a little bit more, you'll see how this will continually to

464
01:41:17.880 --> 01:41:42.789
Sylvia Bouloutas: be really relevant to like all the decisions that you're making and a lot of the progress that you make by Demo Day. It's like really links back to these workshops. So really appreciate everyone being so engaged giving each other feedback being like brave stepping up, you know, saying, you know things about your business that you're assuming, or okrs, that you're curious about learning more, and that you have measure, that you're measuring and ways to refine those so really grateful for everyone. Yeah, Antoine.

