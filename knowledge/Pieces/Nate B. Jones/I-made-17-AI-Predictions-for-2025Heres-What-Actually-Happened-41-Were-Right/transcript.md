# I made 17 AI Predictions for 2025â€”Here's What Actually Happened (41% Were Right)

**Channel**: AI News & Strategy Daily | Nate B Jones  
**Date**: 2025-08-22  
**URL**: https://youtube.com/watch?v=VN8_LWeYlHk  
**Duration**: 0:17:10  
**Views**: 5,610  
**Transcribed**: 2025-08-24  
**Source**: youtube_captions

---

## Transcript

Back in January of 2025, at the beginning of the year, I put my money where my mouth is or I put my predictions out on the table. I listed 17 predictions that I thought would come true in 2025. And just about 8 months have come off the clock at this point. It is up to me to come back and be honest with you about what's working and what's not with my predictions because I believe in laying the cards on the table. All right, so we're going to go through all 17 predictions. I'm going to share with you my grading rubric first and why I'm grading things the way they are for each and you can push back and tell me where you think I'm wrong or where you think I missed something that might shift the grade. So, first we're going to go through what I call the hits, the things that I got right. So, out of 17 predictions, seven, we'll call them home runs. I knocked them out of the park. They absolutely were. Number one, AI creators come out of the closet. I predicted that we would see a world where AI characters and creators compete with human creators. Yes, I'm really a human. I know people sometimes think I'm an AI. I'm an actual human. The beard is real. But AI creators are coming out of the closet. There are AI only fans creators that are earning $10,000 a month or so with apparently 300% revenue growth. So, I'm sure it's much larger now. There are AI native creative agencies out there now. Major platforms are allowing AI content because frankly, it's sticky. I'm going to give myself yes. AI creators did come out of the closet. This is the year of AI creators. It's going to get bigger from here. Maybe they're going to have an AI Nate by this time next year. Who knows? Number two, your feed goes synthetic. So, this is sort of a correlary to number one, right? If you have more AI creators, you have more synthetic content in your social feeds. Well, that one is predictably a hit. Apparently, we are nearing 40% of Instagram feeds being heavily AI influenced. So creative elements with AI, AI creators themselves, etc. AI content generation tools are being integrated deeply into meta so Zuck can get people making more stuff with AI. And increasingly users cannot distinguish AI from human content, which comes down to advances we've seen this year in image and video generation. If you haven't seen Genie 3 from Google, I encourage you to look at some of the videos. It can generate immersive worlds as you navigate them, right? It's one of those things that's really eerie because the world literally doesn't exist until you go there and then it's just it appears. And one of the things we learned from Google in August is that they now have so much confidence in Genie3 that they've actually got a tiny little LLM navigating the world inside the mind of that other LLM. In other words, they have a tiny LLM steering an agent through the world created by the AI Gen3. There's an AI living in the mind of another AI. I did not predict that one, but boy would have been cool if I did. Next hit, the revenge of audio. So, I'm calling out sort of the importance of her like voices and how that's going to be a big part of 2025. We have literally open AI's voice assistant comparisons to her in 2025. I did not make that one up. We have contextually aware AI voice systems being deployed. We have emotional AI voice companions becoming mainstream. It is a big year for voice. Next prediction. I don't think that one's going to be too controversial to say that's a hit. In fact, it's such a hit that when Chad GBT5 came out and the voice changed, the character changed, the way the content comeback changed, people complained. They complain because they liked the voice of the old version of 40 so much. That's how you know it's a hip. Next, your new colleague is an AI for non- tech. 45% of US workers report using AI tools at work. AI adoption is spreading beyond tech into traditional industries. Yeah, workplace integration is accelerating. I'm giving myself mostly a hit for this. I think by the end of the year, it's going to be more true as a hit. It's turning up that way. I will fully agree. We are we are not in every company at the point where you can tag the AI in Slack. In many companies, you can. And I think that it's worth calling out that if that feels strange and science fiction to you, that's more a function of your company context than it is of where the tech is actually at. Next up, a visual AI unicorn or the companionship phenomenon. This idea that we would have digital girlfriends, digital boyfriends, that's got to be a hit. Grock's virtual visual companions are rolling out on a massive scale. People have lots of feelings and thoughts about that, but they're there. The AI companion market as a whole is hitting $120 million plus per year with widespread adoption. It's just exploded. And so, I think that one's a hit. It's going to be even more of a hit in four months at the end of the year. Memory changes everything. Chat GPT is continuing to invest in memory. We now have Claude investing in memory. Cross conversation memory is happening. AI agentic memory is happening with multiple AI agents having different memory strategies. We have tremendous investment in the ability to even partially remember things. By the end of the year, we're going to have even better memory features across more LLMs and more agents. Memory is going to be a really, really big deal. And so I'm going to give myself a hit on that one. I think that's one of the defining AI transformations in 2025. And then the great authentication crisis. Essentially what I suggested is that we are going to have more and more issues with these voices creating deep fakes causing fraud issues etc. It's certainly true that perfect def deep fakes are becoming trivially easy to create. It's true that identity verification is becoming more and more of an issue. we are having to go to greater and greater lengths to prove our identity. And the last piece, the piece that I don't know if it's actually going to come true or not. This was a very specific prediction. I want to be honest about the fact that I don't know that we have this yet and we'll have to just flip the coin for four months to see if it really lands. Despite the overall trend being in my favor here, I did predict that a CEO would have an issue because someone would voice print that CEO from a public earnings statement and then use that CEO's voice to defraud a corporation. Maybe sounds a little sci-fi. I think we have all the building blocks on the table in August of 2025. No one has yet gotten that to happen that I have seen. On the other hand, the devil in me wants to point out if it did happen, would they report it? I don't know. Anyway, I think the trend is in my favor on this one. Now, we're going to move from the seven things that are broadly hits to things that I want to grade myself down on. These are partials. I think that we have we have partial hits on all of these. Uh there's six of them, and I want to go through them. By the way, if you're if you're tracking at home, seven hits out of 17 plus six partials. Yeah, we're not doing too bad. That's that's 13 out of 17. that that are going okay. Let's be honest, no one's perfect, right? All right. Uh, strong partials, AI joins the party. So, AI, human dating platforms launching virtual companions and social settings. This is starting to happen. I think that the blocker here is actually social and etiquette, and we will just have to see how long that takes. I don't think the blocker is necessarily technical, although we may need a breakthrough app that makes it socially acceptable for people to bring their digital companion to lunch with the parents or whatever. That may sound weird and it's going to bring up all kinds of ethics and norms issues. It's going to happen. And so, I also want to call out areas where like on these ones that I'm not entirely like really seeing this year, I want to call out like am I doubling down here or am I walking away and saying I was wrong. I think I'm doubling down. I think we're going to see more here. AI skills ultimatum. So AI literacy is becoming a job requirement for some roles, not for all. Workplace de workplaces are starting to divide over AI adoption. I see that anecdotally with teams training programs are proliferating. I think what makes this a partial is that this is happening in particular sectors of the economy. It's not necessarily happening economywide. And I think that's one of the really interesting lessons of 2025 is that AI transformation is as jagged as the intelligence of AI itself. And I don't think I fully laid that out and appreciated that in January of 2025. So I'm giving myself a partial here. And I'm going to say I am betting that the jaggedness will continue. I am betting that we will see these AI skills ultimatums and AI transformations in pockets. And I am betting that there will be other pockets that are much less changed over the next year or two. So I think that I am revising my thesis a bit here. Number three, big tech agent fiasco. I predicted there would be a bit of a bubble pop here. And I think that the reason that this is a partial is because I specifically predicted somebody would get this so wrong there would be billions of dollars in market capitalization losses. And I can't prove that there has been. Again, people are probably incentivized not to say that too much. So maybe there has been and I just got over optimistic about the economic consequences or overly pessimistic as it were. That being said, the larger trend, big tech did lean really heavily on the Asian hype train and we are seeing a lot of pullback on AI agents because the knowhow to successfully implement an agent that delivers ROI is way behind the hype. The number of people that can do a great AI agent, even one as simple as an NADN agent, is a tenth a tenth of the demand at least. And so 40%ish of AI projects are likely to be canceled in the next uh year or two uh according to widespread reporting um from AI newsshub and other sources. Uh you have had very public failures of AI agents and Gartner itself has predicted widespread agent shakeout. And so to me, it's the classic Gartner hype cycle of the trough trough of disillusionment and then we get to the plateau of productivity. AI agents are headed for the trough of disillusionment. And I say that as someone who's very bullish on agents long term. You're just going to have to go through the fact that a lot of people got hyped up on it, weren't given the tools, could not find people who could actually build and successfully implement them, and got very discouraged. We need more people that can build successful agents in production. So that one's a partial. I don't think that we got the billions in market cap losses, but I think that we did get a little bit of an agent implosion. So, hardware, I am giving myself a partial here because this is behind schedule. I am doubling down on this. I am predicting that this will happen. I'm predicting a new specific hardware device from OpenAI or from others as well. Hardware with AI native is coming. It is going to be an iPhone challenger of some sort. perhaps not immediately positioned to cannibalize the iPhone, but certainly intended to be another major device, a third device along with your laptop and your phone. This is coming. So, I think I'm giving myself credit in doubling down. It is delayed. I don't think that we are going to see something until lateish in 2026 at this point. And so, I can't give myself full credit here, even if I'm bullish long term. Next one. The AGI debate gets weird. I think that this is partial only because of the definition of weirdness and also there's no consensus on AGI definition which I probably should have emphasized more. You do see AI systems achieving high IQ scores and yet they also fail some basic tests. Famously Andre Carpathy called out at YC school that you sometimes have AI still not realizing that 9.11 is a smaller number than 9.89 89 because it just doesn't look that way if you're not reading correctly and you're not doing the actual math. So, the AGI debate is absolutely getting weirder and weirder the more releases we have. And so, I think I'm going to double down on continued weirdness. I think that maybe I will maybe I will back away a little bit from the AGI debate being as central as I think I positioned it in January. I don't think AGI is going to matter as much as I thought. Even if the debate is going to continue to get weird. Okay, last one that's a partial and then we'll get to my misses. I know you guys stayed around for the misses. We'll get to that. AI safety gets personal. So, there's a lot of like early motion toward this. I just think I was too too ahead of the curve. This maybe giving myself too much credit, but like I don't see this fully realized yet. So, there's starting to be some AI offspaces and detox programs emerging. We're starting to see some public health implications of overaffirming AI getting reported widely. Personal AI boundaries are becoming something people talk about. Speaking of companions, it's becoming an issue in human romantic relationships. Do you have a digital companion? Do we have boundaries around that, etc. Uh, wellness industry is pivoting toward AI concerns as well, but it's not really fully there. To me, this feels like I want to double down, but it feels like it's running a little bit behind where I thought it would be. And so, I think it's more of a 2026, 2027 thing to get widespread. Okay. Okay. I know you were waiting for this. The misses. What has been too early and too wide? Sort of just not on the table. We have four things cuz remember we're doing seven. We did seven that were hit, six that were partials. Now, we have to do the fours that were terrible that I missed. I predicted that there would be AI consciousness activism at board meetings from people who believe in AI consciousness. There are certainly people who believe in AI consciousness, but it's been mostly an academic discussion. It's been mostly a chat room discussion. It has not yet disrupted any board meetings. It seems somewhat low probability that it will. It's I'm giving myself a miss on this one. I think I just did not correctly predict this. Even though I did predict that there would be some degree of consciousness conversation, that's not the same thing as saying that there would be a sort of disruptor that's like allin for AI labor rights at the board meeting. I just that didn't I think the smart mirror that I predicted was a miss too. I predicted that there would be a lot of investments in smart mirrors because people want to get into visual AI, right? They want to try on outfits. They want to exercise things that they can do at home that need feedback that are visual from the AI. We've had a few fitness and health things. It's not It's not a major breakthrough. It's not on track to become a household product. I just missed this one. I'm not going to double down. Third miss, humanoid robots will have their iPhone moment. I predicted specifically that there would be a robot 2026 Super Bowl commercial, which I still have time on the clock for, so I'm not giving up on that. But I think largely speaking, we still don't have the iPhone moment for robots. We are we are still a year or two away and it's been that way for a bit. I know there are now production robots on sale that can solve household problems. I saw one that folds your laundry. Looks way too expensive to fold my laundry. I think I was too early on this one. I'm not going to double down. Last one. AI weddings. I predicted that an AI relationship moment would turn into a wedding. As much as we've talked a lot about companionship and the social implications of AI, I've seen no traction on AI weddings anywhere in the world, no legal framework, nobody stepping up to say, "Come to our country. We will do AI weddings for you." It might still happen, but I think I just jumped in the water too early on this one. So, I'm not going to double down there. I think the companionship thing is sticking around. I think weddings are hard to predict. So, there you go. Uh 41% of my of my predictions were broadly correct. 35% eh give yourself some partial credit and 25% 24% no good at all just didn't get it right what do you think about what's next what would I what would I wish I had added to these 17 predictions that's the last part of this if I if I look at what has happened so far if I could go back and do it again what are three things that I would I think first and foremost I should have predicted the kind of LLM affinity that we saw with the chat GBT5 roll out where people just demand anded 40 to come back. I had all the ingredients there. I talked about companionship, emotional bonding. I should have seen it. I didn't see it. Didn't predict it. Don't get to credit it. Another one that I should have predicted. I should have leaned heavier on this being the year of code. AI and code is something that has been so heavily invested in by every single major lab and frankly by a lot of the tool builders themselves. And I just did not put enough effort into sort of investing in smart predictions there. I think if I had been smarter, I would have seen the relationship between code and agents. I would have seen the importance of code in flagship releases do it again. All the ingredients are on the table. I could have seen it. And then three, like stepping back, I did not correctly predict the downfall of llama and the proliferation of open- source. There are now hundreds and hundreds of open source models that are excellent. And you may hear about open AI models, but there are lots and lots of Chinese models that are incredible as well that are open source, open weights that you can then run on your own local machines, and you don't have to run on Chinese servers at all. I should have done a better job noting how quickly LLM technology proliferates and that was a miss on my part, too. So, there you go. Three misses, things that I think I should have predicted, the 17 original predictions and how I broke them down. What do you think I missed? Where do you think I graded wrong? Let me know in the comments.

---

## Timestamped Transcript

[0:00:00] Back in January of 2025, at the
[0:00:02] beginning of the year, I put my money
[0:00:05] where my mouth is or I put my
[0:00:07] predictions out on the table. I listed
[0:00:09] 17 predictions that I thought would come
[0:00:12] true in 2025. And just about 8 months
[0:00:16] have come off the clock at this point.
[0:00:18] It is up to me to come back and be
[0:00:20] honest with you about what's working and
[0:00:21] what's not with my predictions because I
[0:00:24] believe in laying the cards on the
[0:00:25] table. All right, so we're going to go
[0:00:26] through all 17 predictions. I'm going to
[0:00:28] share with you my grading rubric first
[0:00:31] and why I'm grading things the way they
[0:00:33] are for each and you can push back and
[0:00:35] tell me where you think I'm wrong or
[0:00:38] where you think I missed something that
[0:00:39] might shift the grade. So, first we're
[0:00:41] going to go through what I call the
[0:00:44] hits, the things that I got right. So,
[0:00:46] out of 17 predictions, seven, we'll call
[0:00:48] them home runs. I knocked them out of
[0:00:50] the park. They absolutely were. Number
[0:00:52] one,
[0:00:53] AI creators come out of the closet. I
[0:00:56] predicted that we would see a world
[0:00:58] where AI characters and creators compete
[0:01:01] with human creators. Yes, I'm really a
[0:01:03] human. I know people sometimes think I'm
[0:01:04] an AI. I'm an actual human. The beard is
[0:01:06] real. But AI creators are coming out of
[0:01:08] the closet. There are AI only fans
[0:01:10] creators that are earning $10,000 a
[0:01:12] month or so with apparently 300% revenue
[0:01:16] growth. So, I'm sure it's much larger
[0:01:17] now. There are AI native creative
[0:01:19] agencies out there now. Major platforms
[0:01:21] are allowing AI content because frankly,
[0:01:23] it's sticky. I'm going to give myself
[0:01:26] yes. AI creators did come out of the
[0:01:28] closet. This is the year of AI creators.
[0:01:30] It's going to get bigger from here.
[0:01:32] Maybe they're going to have an AI Nate
[0:01:33] by this time next year. Who knows?
[0:01:35] Number two, your feed goes synthetic.
[0:01:39] So, this is sort of a correlary to
[0:01:40] number one, right? If you have more AI
[0:01:42] creators, you have more synthetic
[0:01:43] content in your social feeds. Well, that
[0:01:46] one is predictably a hit. Apparently, we
[0:01:49] are nearing 40% of Instagram feeds being
[0:01:52] heavily AI influenced. So creative
[0:01:54] elements with AI, AI creators
[0:01:56] themselves, etc. AI content generation
[0:01:58] tools are being integrated deeply into
[0:02:00] meta so Zuck can get people making more
[0:02:03] stuff with AI. And increasingly users
[0:02:06] cannot distinguish AI from human
[0:02:08] content, which comes down to advances
[0:02:09] we've seen this year in image and video
[0:02:12] generation. If you haven't seen Genie 3
[0:02:16] from Google, I encourage you to look at
[0:02:18] some of the videos. It can generate
[0:02:19] immersive worlds as you navigate them,
[0:02:22] right? It's one of those things that's
[0:02:23] really eerie because the world literally
[0:02:25] doesn't exist until you go there and
[0:02:26] then it's just it appears. And one of
[0:02:29] the things we learned from Google in
[0:02:31] August is that they now have so much
[0:02:34] confidence in Genie3 that they've
[0:02:36] actually got a tiny little LLM
[0:02:38] navigating the world inside the mind of
[0:02:40] that other LLM. In other words, they
[0:02:42] have a tiny LLM steering an agent
[0:02:44] through the world created by the AI
[0:02:47] Gen3. There's an AI living in the mind
[0:02:50] of another AI. I did not predict that
[0:02:52] one, but boy would have been cool if I
[0:02:54] did. Next hit, the revenge of audio. So,
[0:02:57] I'm calling out sort of the importance
[0:02:59] of her like voices and how that's going
[0:03:02] to be a big part of 2025. We have
[0:03:05] literally open AI's voice assistant
[0:03:07] comparisons to her in 2025. I did not
[0:03:10] make that one up. We have contextually
[0:03:12] aware AI voice systems being deployed.
[0:03:14] We have emotional AI voice companions
[0:03:16] becoming mainstream. It is a big year
[0:03:19] for voice. Next prediction. I don't
[0:03:21] think that one's going to be too
[0:03:22] controversial to say that's a hit. In
[0:03:24] fact, it's such a hit that when Chad
[0:03:25] GBT5 came out and the voice changed, the
[0:03:28] character changed, the way the content
[0:03:30] comeback changed, people complained.
[0:03:32] They complain because they liked the
[0:03:33] voice of the old version of 40 so much.
[0:03:36] That's how you know it's a hip. Next,
[0:03:38] your new colleague is an AI for non-
[0:03:41] tech. 45% of US workers report using AI
[0:03:44] tools at work. AI adoption is spreading
[0:03:46] beyond tech into traditional industries.
[0:03:48] Yeah, workplace integration is
[0:03:49] accelerating. I'm giving myself mostly a
[0:03:52] hit for this. I think by the end of the
[0:03:54] year, it's going to be more true as a
[0:03:56] hit. It's turning up that way. I will
[0:03:58] fully agree. We are we are not in every
[0:04:02] company at the point where you can tag
[0:04:04] the AI in Slack. In many companies, you
[0:04:07] can. And I think that it's worth calling
[0:04:09] out that if that feels strange and
[0:04:10] science fiction to you, that's more a
[0:04:12] function of your company context than it
[0:04:15] is of where the tech is actually at.
[0:04:17] Next up, a visual AI unicorn or the
[0:04:20] companionship phenomenon. This idea that
[0:04:21] we would have digital girlfriends,
[0:04:23] digital boyfriends, that's got to be a
[0:04:25] hit. Grock's virtual visual companions
[0:04:27] are rolling out on a massive scale.
[0:04:29] People have lots of feelings and
[0:04:31] thoughts about that, but they're there.
[0:04:32] The AI companion market as a whole is
[0:04:34] hitting $120 million plus per year with
[0:04:37] widespread adoption. It's just exploded.
[0:04:39] And so, I think that one's a hit. It's
[0:04:41] going to be even more of a hit in four
[0:04:42] months at the end of the year. Memory
[0:04:44] changes everything. Chat GPT is
[0:04:47] continuing to invest in memory. We now
[0:04:49] have Claude investing in memory. Cross
[0:04:52] conversation memory is happening. AI
[0:04:55] agentic memory is happening with
[0:04:56] multiple AI agents having different
[0:04:58] memory strategies. We have tremendous
[0:05:01] investment in the ability to even
[0:05:03] partially remember things. By the end of
[0:05:06] the year, we're going to have even
[0:05:07] better memory features across more LLMs
[0:05:09] and more agents. Memory is going to be a
[0:05:11] really, really big deal. And so I'm
[0:05:14] going to give myself a hit on that one.
[0:05:15] I think that's one of the defining AI
[0:05:17] transformations in 2025. And then the
[0:05:20] great authentication crisis. Essentially
[0:05:22] what I suggested is that we are going to
[0:05:24] have more and more issues with these
[0:05:26] voices creating deep fakes causing fraud
[0:05:29] issues etc. It's certainly true that
[0:05:31] perfect def deep fakes are becoming
[0:05:33] trivially easy to create. It's true that
[0:05:36] identity verification is becoming more
[0:05:38] and more of an issue. we are having to
[0:05:40] go to greater and greater lengths to
[0:05:42] prove our identity. And the last piece,
[0:05:45] the piece that I don't know if it's
[0:05:46] actually going to come true or not. This
[0:05:48] was a very specific prediction. I want
[0:05:49] to be honest about the fact that I don't
[0:05:51] know that we have this yet and we'll
[0:05:52] have to just flip the coin for four
[0:05:54] months to see if it really lands.
[0:05:55] Despite the overall trend being in my
[0:05:57] favor here, I did predict that a CEO
[0:06:01] would have an issue because someone
[0:06:03] would voice print that CEO from a public
[0:06:06] earnings statement and then use that
[0:06:08] CEO's voice to defraud a corporation.
[0:06:12] Maybe sounds a little sci-fi. I think we
[0:06:14] have all the building blocks on the
[0:06:15] table in August of 2025. No one has yet
[0:06:18] gotten that to happen that I have seen.
[0:06:20] On the other hand, the devil in me wants
[0:06:22] to point out if it did happen, would
[0:06:24] they report it? I don't know. Anyway, I
[0:06:27] think the trend is in my favor on this
[0:06:28] one. Now, we're going to move from the
[0:06:30] seven things that are broadly hits to
[0:06:32] things that I want to grade myself down
[0:06:33] on. These are partials. I think that we
[0:06:35] have we have partial hits on all of
[0:06:37] these. Uh there's six of them, and I
[0:06:39] want to go through them. By the way, if
[0:06:41] you're if you're tracking at home, seven
[0:06:43] hits out of 17 plus six partials. Yeah,
[0:06:46] we're not doing too bad. That's that's
[0:06:48] 13 out of 17. that that are going okay.
[0:06:50] Let's be honest, no one's perfect,
[0:06:52] right? All right. Uh, strong partials,
[0:06:54] AI joins the party. So, AI, human dating
[0:06:57] platforms launching virtual companions
[0:07:00] and social settings. This is starting to
[0:07:02] happen. I think that the blocker here is
[0:07:04] actually social and etiquette, and we
[0:07:06] will just have to see how long that
[0:07:08] takes. I don't think the blocker is
[0:07:09] necessarily technical, although we may
[0:07:11] need a breakthrough app that makes it
[0:07:13] socially acceptable for people to bring
[0:07:16] their digital companion to lunch with
[0:07:19] the parents or whatever. That may sound
[0:07:21] weird and it's going to bring up all
[0:07:22] kinds of ethics and norms issues. It's
[0:07:24] going to happen. And so, I also want to
[0:07:26] call out areas where like on these ones
[0:07:28] that I'm not entirely like really seeing
[0:07:30] this year, I want to call out like am I
[0:07:32] doubling down here or am I walking away
[0:07:34] and saying I was wrong. I think I'm
[0:07:36] doubling down. I think we're going to
[0:07:37] see more here. AI skills ultimatum. So
[0:07:40] AI literacy is becoming a job
[0:07:42] requirement for some roles, not for all.
[0:07:45] Workplace de workplaces are starting to
[0:07:48] divide over AI adoption. I see that
[0:07:50] anecdotally with teams training programs
[0:07:52] are proliferating. I think what makes
[0:07:55] this a partial is that this is happening
[0:07:57] in particular sectors of the economy.
[0:07:59] It's not necessarily happening
[0:08:00] economywide. And I think that's one of
[0:08:02] the really interesting lessons of 2025
[0:08:05] is that AI transformation is as jagged
[0:08:08] as the intelligence of AI itself. And I
[0:08:11] don't think I fully laid that out and
[0:08:13] appreciated that in January of 2025. So
[0:08:15] I'm giving myself a partial here. And
[0:08:17] I'm going to say I am betting that the
[0:08:19] jaggedness will continue. I am betting
[0:08:21] that we will see these AI skills
[0:08:23] ultimatums and AI transformations in
[0:08:25] pockets. And I am betting that there
[0:08:27] will be other pockets that are much less
[0:08:30] changed over the next year or two. So I
[0:08:32] think that I am revising my thesis a bit
[0:08:34] here. Number three, big tech agent
[0:08:37] fiasco. I predicted there would be a bit
[0:08:39] of a bubble pop here. And I think that
[0:08:42] the reason that this is a partial is
[0:08:44] because I specifically predicted
[0:08:47] somebody would get this so wrong there
[0:08:48] would be billions of dollars in market
[0:08:50] capitalization losses. And I can't prove
[0:08:52] that there has been. Again, people are
[0:08:54] probably incentivized not to say that
[0:08:56] too much. So maybe there has been and I
[0:08:57] just got over optimistic about the
[0:08:59] economic consequences or overly
[0:09:01] pessimistic as it were. That being said,
[0:09:03] the larger trend, big tech did lean
[0:09:06] really heavily on the Asian hype train
[0:09:08] and we are seeing a lot of pullback on
[0:09:11] AI agents because the knowhow to
[0:09:13] successfully implement an agent that
[0:09:15] delivers ROI is way behind the hype. The
[0:09:18] number of people that can do a great AI
[0:09:21] agent, even one as simple as an NADN
[0:09:23] agent, is a tenth a tenth
[0:09:26] of the demand at least. And so 40%ish of
[0:09:31] AI projects are likely to be canceled in
[0:09:33] the next uh year or two uh according to
[0:09:35] widespread reporting um from AI newsshub
[0:09:38] and other sources. Uh you have had very
[0:09:41] public failures of AI agents and Gartner
[0:09:44] itself has predicted widespread agent
[0:09:47] shakeout. And so to me, it's the classic
[0:09:49] Gartner hype cycle of the trough trough
[0:09:51] of disillusionment and then we get to
[0:09:53] the plateau of productivity. AI agents
[0:09:55] are headed for the trough of
[0:09:56] disillusionment. And I say that as
[0:09:58] someone who's very bullish on agents
[0:09:59] long term. You're just going to have to
[0:10:01] go through the fact that a lot of people
[0:10:03] got hyped up on it, weren't given the
[0:10:05] tools, could not find people who could
[0:10:07] actually build and successfully
[0:10:08] implement them, and got very
[0:10:09] discouraged. We need more people that
[0:10:11] can build successful agents in
[0:10:14] production. So that one's a partial. I
[0:10:16] don't think that we got the billions in
[0:10:17] market cap losses, but I think that we
[0:10:18] did get a little bit of an agent
[0:10:20] implosion. So, hardware, I am giving
[0:10:22] myself a partial here because this is
[0:10:25] behind schedule. I am doubling down on
[0:10:27] this. I am predicting that this will
[0:10:29] happen. I'm predicting a new specific
[0:10:31] hardware device from OpenAI or from
[0:10:34] others as well. Hardware with AI native
[0:10:37] is coming. It is going to be an iPhone
[0:10:39] challenger of some sort. perhaps not
[0:10:40] immediately positioned to cannibalize
[0:10:42] the iPhone, but certainly intended to be
[0:10:45] another major device, a third device
[0:10:47] along with your laptop and your phone.
[0:10:49] This is coming. So, I think I'm giving
[0:10:50] myself credit in doubling down. It is
[0:10:52] delayed. I don't think that we are going
[0:10:54] to see something until lateish in 2026
[0:10:57] at this point. And so, I can't give
[0:11:00] myself full credit here, even if I'm
[0:11:01] bullish long term. Next one. The AGI
[0:11:03] debate gets weird. I think that this is
[0:11:06] partial only because of the definition
[0:11:08] of weirdness and also there's no
[0:11:11] consensus on AGI definition which I
[0:11:13] probably should have emphasized more.
[0:11:14] You do see AI systems achieving high IQ
[0:11:17] scores and yet they also fail some basic
[0:11:19] tests. Famously Andre Carpathy called
[0:11:22] out at YC school that you sometimes have
[0:11:24] AI still not realizing that 9.11 is a
[0:11:27] smaller number than 9.89 89 because it
[0:11:31] just doesn't look that way if you're not
[0:11:33] reading correctly and you're not doing
[0:11:35] the actual math. So, the AGI debate is
[0:11:38] absolutely getting weirder and weirder
[0:11:41] the more releases we have. And so, I
[0:11:43] think I'm going to double down on
[0:11:45] continued weirdness. I think that maybe
[0:11:48] I will maybe I will back away a little
[0:11:51] bit from the AGI debate being as central
[0:11:54] as I think I positioned it in January. I
[0:11:56] don't think AGI is going to matter as
[0:11:58] much as I thought. Even if the debate is
[0:12:01] going to continue to get weird. Okay,
[0:12:03] last one that's a partial and then we'll
[0:12:05] get to my misses. I know you guys stayed
[0:12:06] around for the misses. We'll get to
[0:12:08] that. AI safety gets personal. So,
[0:12:12] there's a lot of like early motion
[0:12:14] toward this. I just think I was too too
[0:12:16] ahead of the curve. This maybe giving
[0:12:18] myself too much credit, but like I don't
[0:12:20] see this fully realized yet. So, there's
[0:12:22] starting to be some AI offspaces and
[0:12:24] detox programs emerging. We're starting
[0:12:26] to see some public health implications
[0:12:28] of overaffirming AI getting reported
[0:12:30] widely. Personal AI boundaries are
[0:12:32] becoming something people talk about.
[0:12:34] Speaking of companions, it's becoming an
[0:12:35] issue in human romantic relationships.
[0:12:37] Do you have a digital companion? Do we
[0:12:39] have boundaries around that, etc. Uh,
[0:12:41] wellness industry is pivoting toward AI
[0:12:43] concerns as well, but it's not really
[0:12:45] fully there. To me, this feels like I
[0:12:47] want to double down, but it feels like
[0:12:48] it's running a little bit behind where I
[0:12:50] thought it would be. And so, I think
[0:12:51] it's more of a 2026, 2027 thing to get
[0:12:54] widespread. Okay. Okay. I know you were
[0:12:56] waiting for this. The misses. What has
[0:12:59] been too early and too wide? Sort of
[0:13:02] just not on the table. We have four
[0:13:05] things cuz remember we're doing seven.
[0:13:06] We did seven that were hit, six that
[0:13:08] were partials. Now, we have to do the
[0:13:10] fours that were terrible that I missed.
[0:13:12] I predicted that there would be AI
[0:13:14] consciousness activism at board meetings
[0:13:16] from people who believe in AI
[0:13:18] consciousness. There are certainly
[0:13:20] people who believe in AI consciousness,
[0:13:22] but it's been mostly an academic
[0:13:24] discussion. It's been mostly a chat room
[0:13:26] discussion. It has not yet disrupted any
[0:13:28] board meetings. It seems somewhat low
[0:13:30] probability that it will. It's I'm
[0:13:32] giving myself a miss on this one. I
[0:13:34] think I just did not correctly predict
[0:13:36] this. Even though I did predict that
[0:13:38] there would be some degree of
[0:13:40] consciousness conversation, that's not
[0:13:42] the same thing as saying that there
[0:13:43] would be a sort of disruptor that's like
[0:13:45] allin for AI labor rights at the board
[0:13:47] meeting. I just that didn't I think the
[0:13:49] smart mirror that I predicted was a miss
[0:13:51] too. I predicted that there would be a
[0:13:52] lot of investments in smart mirrors
[0:13:54] because people want to get into visual
[0:13:58] AI, right? They want to try on outfits.
[0:14:00] They want to exercise things that they
[0:14:01] can do at home that need feedback that
[0:14:03] are visual from the AI. We've had a few
[0:14:05] fitness and health things. It's not It's
[0:14:08] not a major breakthrough. It's not on
[0:14:10] track to become a household product. I
[0:14:12] just missed this one. I'm not going to
[0:14:14] double down. Third miss, humanoid robots
[0:14:17] will have their iPhone moment. I
[0:14:19] predicted specifically that there would
[0:14:20] be a robot 2026 Super Bowl commercial,
[0:14:23] which I still have time on the clock
[0:14:24] for, so I'm not giving up on that. But I
[0:14:26] think largely speaking, we still don't
[0:14:29] have the iPhone moment for robots. We
[0:14:32] are we are still a year or two away and
[0:14:35] it's been that way for a bit. I know
[0:14:37] there are now production robots on sale
[0:14:40] that can solve household problems. I saw
[0:14:42] one that folds your laundry. Looks way
[0:14:44] too expensive to fold my laundry. I
[0:14:46] think I was too early on this one. I'm
[0:14:47] not going to double down. Last one. AI
[0:14:50] weddings. I predicted that an AI
[0:14:52] relationship moment would turn into a
[0:14:53] wedding. As much as we've talked a lot
[0:14:55] about companionship and the social
[0:14:56] implications of AI, I've seen no
[0:14:59] traction on AI weddings anywhere in the
[0:15:01] world, no legal framework, nobody
[0:15:03] stepping up to say, "Come to our
[0:15:04] country. We will do AI weddings for
[0:15:06] you." It might still happen, but I think
[0:15:08] I just jumped in the water too early on
[0:15:10] this one. So, I'm not going to double
[0:15:12] down there. I think the companionship
[0:15:13] thing is sticking around. I think
[0:15:14] weddings are hard to predict. So, there
[0:15:17] you go. Uh 41% of my of my predictions
[0:15:20] were broadly correct. 35% eh give
[0:15:23] yourself some partial credit and 25% 24%
[0:15:27] no good at all just didn't get it right
[0:15:29] what do you think about what's next what
[0:15:31] would I what would I wish I had added to
[0:15:34] these 17 predictions that's the last
[0:15:36] part of this if I if I look at what has
[0:15:38] happened so far if I could go back and
[0:15:40] do it again what are three things that I
[0:15:42] would I think first and foremost I
[0:15:44] should have predicted the kind of LLM
[0:15:47] affinity that we saw with the chat GBT5
[0:15:49] roll out where people just demand anded
[0:15:52] 40 to come back. I had all the
[0:15:54] ingredients there. I talked about
[0:15:55] companionship, emotional bonding. I
[0:15:57] should have seen it. I didn't see it.
[0:15:59] Didn't predict it. Don't get to credit
[0:16:00] it. Another one that I should have
[0:16:01] predicted. I should have leaned heavier
[0:16:04] on this being the year of code. AI and
[0:16:06] code is something that has been so
[0:16:08] heavily invested in by every single
[0:16:10] major lab and frankly by a lot of the
[0:16:12] tool builders themselves. And I just did
[0:16:14] not put enough effort into sort of
[0:16:16] investing in smart predictions there. I
[0:16:18] think if I had been smarter, I would
[0:16:19] have seen the relationship between code
[0:16:21] and agents. I would have seen the
[0:16:23] importance of code in flagship releases
[0:16:25] do it again. All the ingredients are on
[0:16:27] the table. I could have seen it. And
[0:16:29] then three, like stepping back, I did
[0:16:31] not correctly predict the downfall of
[0:16:35] llama and the proliferation of open-
[0:16:37] source. There are now hundreds and
[0:16:39] hundreds of open source models that are
[0:16:41] excellent. And you may hear about open
[0:16:42] AI models, but there are lots and lots
[0:16:44] of Chinese models that are incredible as
[0:16:46] well that are open source, open weights
[0:16:48] that you can then run on your own local
[0:16:49] machines, and you don't have to run on
[0:16:51] Chinese servers at all. I should have
[0:16:53] done a better job noting how quickly LLM
[0:16:56] technology proliferates and that was a
[0:16:58] miss on my part, too. So, there you go.
[0:17:00] Three misses, things that I think I
[0:17:01] should have predicted, the 17 original
[0:17:03] predictions and how I broke them down.
[0:17:05] What do you think I missed? Where do you
[0:17:07] think I graded wrong? Let me know in the
[0:17:10] comments.

---

*Extracted from YouTube Auto-generated captions*